{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Music Recommendation Systems**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Context**\n",
    "\n",
    "With the advent of technology, societies have become more efficient with their lives. But at the same time, individual human lives have become much more fast-paced and distracted by leaving little time to explore artistic pursuits. Also, technology has made significant advancements in the ability to coexist with art and general entertainment. In fact, it has made it easier for humans with a shortage of time to find and consume good content. Therefore, one of the key challenges for the companies is to be able to figure out what kind of content their customers are most likely to consume. Almost every internet-based company's revenue relies on the time consumers spend on their platforms. These companies need to be able to figure out what kind of content is needed in order to increase the time spent by customers on their platform and make their experience better.\n",
    "Spotify is one such audio content provider that has got a huge market base across the world. It has grown significantly because of its ability to recommend the ‘best’ next song to each and every customer based on the huge preference database they have gathered over time like millions of customers and billions of songs. This is done by using smart recommendation systems that can recommend songs based on the users’ likes/dislikes\n",
    "\n",
    "### **Objective**\n",
    "\n",
    "To recommend songs to a user based on their likelihood of liking those songs.\n",
    "\n",
    "### **The key questions** \n",
    "- What are all songs they have listened to?\n",
    "- What are the most favored songs and artists?\n",
    "\n",
    "### **Problem Formulation**\n",
    "Build a recommendation system to propose the top 10 songs for a user based on the likelihood of listening to those songs.\n",
    "\n",
    "### **Data Dictionary**\n",
    "\n",
    "The core data is the Taste Profile Subset released by The Echo Nest as part of the Million Song Dataset. There are two files in this dataset. One contains the details about the song id, titles, release, artist name, and the year of release. The second file contains the user id, song id, and the play count of users.\n",
    "\n",
    "song_data\n",
    "song_id - A unique id given to every song\n",
    "title - Title of the song\n",
    "Release - Name of the released album\n",
    "Artist_name - Name of the artist \n",
    "year - Year of release\n",
    "count_data\n",
    "user _id - A unique id given to the user\n",
    "song_id - A unique id given to the song\n",
    "play_count - Number of times the song was played\n",
    "\n",
    "###Data Source\n",
    "http://millionsongdataset.com/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity # to compute the cosine similarity between two vectors\n",
    "from collections import defaultdict # dictionary output that doesn't raise a key error \n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading datasets\n",
    "count_df = pd.read_csv('count_data.csv')\n",
    "song_df = pd.read_csv('song_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>play_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOAKIMP12A8C130995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBBMDR12A8C13253B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBXHDL12A81C204C0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBYHAJ12A6701BF1D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SODACBL12A8C13C273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SODDNQT12A6D4F5F7E</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SODXRTY12AB0180F3B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOFGUAY12AB017B0A8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOFRQTD12A81C233C0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOHQWYZ12A6D4FA701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                   user_id             song_id  \\\n",
       "0           0  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAKIMP12A8C130995   \n",
       "1           1  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBBMDR12A8C13253B   \n",
       "2           2  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBXHDL12A81C204C0   \n",
       "3           3  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBYHAJ12A6701BF1D   \n",
       "4           4  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SODACBL12A8C13C273   \n",
       "5           5  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SODDNQT12A6D4F5F7E   \n",
       "6           6  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SODXRTY12AB0180F3B   \n",
       "7           7  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOFGUAY12AB017B0A8   \n",
       "8           8  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOFRQTD12A81C233C0   \n",
       "9           9  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOHQWYZ12A6D4FA701   \n",
       "\n",
       "   play_count  \n",
       "0           1  \n",
       "1           2  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "5           5  \n",
       "6           1  \n",
       "7           1  \n",
       "8           1  \n",
       "9           1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOQMMHC12AB0180CB8</td>\n",
       "      <td>Silent Night</td>\n",
       "      <td>Monster Ballads X-Mas</td>\n",
       "      <td>Faster Pussy cat</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOVFVAK12A8C1350D9</td>\n",
       "      <td>Tanssi vaan</td>\n",
       "      <td>Karkuteillä</td>\n",
       "      <td>Karkkiautomaatti</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOGTUKN12AB017F4F1</td>\n",
       "      <td>No One Could Ever</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Hudson Mohawke</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOBNYVR12A8C13558C</td>\n",
       "      <td>Si Vos Querés</td>\n",
       "      <td>De Culo</td>\n",
       "      <td>Yerba Brava</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOHSBXH12A8C13B0DF</td>\n",
       "      <td>Tangle Of Aspens</td>\n",
       "      <td>Rene Ablaze Presents Winter Sessions</td>\n",
       "      <td>Der Mystic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SOZVAPQ12A8C13B63C</td>\n",
       "      <td>Symphony No. 1 G minor \"Sinfonie Serieuse\"/All...</td>\n",
       "      <td>Berwald: Symphonies Nos. 1/2/3/4</td>\n",
       "      <td>David Montgomery</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SOQVRHI12A6D4FB2D7</td>\n",
       "      <td>We Have Got Love</td>\n",
       "      <td>Strictly The Best Vol. 34</td>\n",
       "      <td>Sasha / Turbulence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SOEYRFT12AB018936C</td>\n",
       "      <td>2 Da Beat Ch'yall</td>\n",
       "      <td>Da Bomb</td>\n",
       "      <td>Kris Kross</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SOPMIYT12A6D4F851E</td>\n",
       "      <td>Goodbye</td>\n",
       "      <td>Danny Boy</td>\n",
       "      <td>Joseph Locke</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SOJCFMH12A8C13B0C2</td>\n",
       "      <td>Mama_ mama can't you see ?</td>\n",
       "      <td>March to cadence with the US marines</td>\n",
       "      <td>The Sun Harbor's Chorus-Documentary Recordings</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              song_id                                              title  \\\n",
       "0  SOQMMHC12AB0180CB8                                       Silent Night   \n",
       "1  SOVFVAK12A8C1350D9                                        Tanssi vaan   \n",
       "2  SOGTUKN12AB017F4F1                                  No One Could Ever   \n",
       "3  SOBNYVR12A8C13558C                                      Si Vos Querés   \n",
       "4  SOHSBXH12A8C13B0DF                                   Tangle Of Aspens   \n",
       "5  SOZVAPQ12A8C13B63C  Symphony No. 1 G minor \"Sinfonie Serieuse\"/All...   \n",
       "6  SOQVRHI12A6D4FB2D7                                   We Have Got Love   \n",
       "7  SOEYRFT12AB018936C                                  2 Da Beat Ch'yall   \n",
       "8  SOPMIYT12A6D4F851E                                            Goodbye   \n",
       "9  SOJCFMH12A8C13B0C2                         Mama_ mama can't you see ?   \n",
       "\n",
       "                                release  \\\n",
       "0                 Monster Ballads X-Mas   \n",
       "1                           Karkuteillä   \n",
       "2                                Butter   \n",
       "3                               De Culo   \n",
       "4  Rene Ablaze Presents Winter Sessions   \n",
       "5      Berwald: Symphonies Nos. 1/2/3/4   \n",
       "6             Strictly The Best Vol. 34   \n",
       "7                               Da Bomb   \n",
       "8                             Danny Boy   \n",
       "9  March to cadence with the US marines   \n",
       "\n",
       "                                      artist_name  year  \n",
       "0                                Faster Pussy cat  2003  \n",
       "1                                Karkkiautomaatti  1995  \n",
       "2                                  Hudson Mohawke  2006  \n",
       "3                                     Yerba Brava  2003  \n",
       "4                                      Der Mystic     0  \n",
       "5                                David Montgomery     0  \n",
       "6                              Sasha / Turbulence     0  \n",
       "7                                      Kris Kross  1993  \n",
       "8                                    Joseph Locke     0  \n",
       "9  The Sun Harbor's Chorus-Documentary Recordings     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(count_df.head(10), song_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000000 entries, 0 to 1999999\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Dtype \n",
      "---  ------      ----- \n",
      " 0   Unnamed: 0  int64 \n",
      " 1   user_id     object\n",
      " 2   song_id     object\n",
      " 3   play_count  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 61.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# datasets info\n",
    "count_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count    Dtype \n",
      "---  ------       --------------    ----- \n",
      " 0   song_id      1000000 non-null  object\n",
      " 1   title        999985 non-null   object\n",
      " 2   release      999995 non-null   object\n",
      " 3   artist_name  1000000 non-null  object\n",
      " 4   year         1000000 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 38.1+ MB\n"
     ]
    }
   ],
   "source": [
    "song_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Observations and Insights:**\n",
    "- The count_df dataframe contains user_id, song_id, and the number of times a particular song has been played by a particular user. There are 4 columns and 20,000,000 observations in the dataset.\n",
    "- The unnamed: 0 column seems like the index of the dataframe. We can drop this column.\n",
    "- The song_df data has information/features of the song - title, released album, artist name, year of release. There are 5 columns and 10,000,00 observations in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# checking for duplicated observations\n",
    "print(song_df.duplicated().sum())\n",
    "print(count_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping duplicates from song_df\n",
    "song_df = song_df.drop_duplicates(['song_id'])\n",
    "song_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>play_count</th>\n",
       "      <th>title</th>\n",
       "      <th>release</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOAKIMP12A8C130995</td>\n",
       "      <td>1</td>\n",
       "      <td>The Cove</td>\n",
       "      <td>Thicker Than Water</td>\n",
       "      <td>Jack Johnson</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBBMDR12A8C13253B</td>\n",
       "      <td>2</td>\n",
       "      <td>Entre Dos Aguas</td>\n",
       "      <td>Flamenco Para Niños</td>\n",
       "      <td>Paco De Lucia</td>\n",
       "      <td>1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBXHDL12A81C204C0</td>\n",
       "      <td>1</td>\n",
       "      <td>Stronger</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Kanye West</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBYHAJ12A6701BF1D</td>\n",
       "      <td>1</td>\n",
       "      <td>Constellations</td>\n",
       "      <td>In Between Dreams</td>\n",
       "      <td>Jack Johnson</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SODACBL12A8C13C273</td>\n",
       "      <td>1</td>\n",
       "      <td>Learn To Fly</td>\n",
       "      <td>There Is Nothing Left To Lose</td>\n",
       "      <td>Foo Fighters</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user_id             song_id  play_count  \\\n",
       "0  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAKIMP12A8C130995           1   \n",
       "1  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBBMDR12A8C13253B           2   \n",
       "2  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBXHDL12A81C204C0           1   \n",
       "3  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBYHAJ12A6701BF1D           1   \n",
       "4  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SODACBL12A8C13C273           1   \n",
       "\n",
       "             title                        release    artist_name  year  \n",
       "0         The Cove             Thicker Than Water   Jack Johnson     0  \n",
       "1  Entre Dos Aguas            Flamenco Para Niños  Paco De Lucia  1976  \n",
       "2         Stronger                     Graduation     Kanye West  2007  \n",
       "3   Constellations              In Between Dreams   Jack Johnson  2005  \n",
       "4     Learn To Fly  There Is Nothing Left To Lose   Foo Fighters  1999  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging datasets \n",
    "df = pd.merge(count_df, song_df, on='song_id', how='left')\n",
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000000, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>play_count</th>\n",
       "      <th>title</th>\n",
       "      <th>release</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54961</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>The Cove</td>\n",
       "      <td>Thicker Than Water</td>\n",
       "      <td>Jack Johnson</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54961</td>\n",
       "      <td>413</td>\n",
       "      <td>2</td>\n",
       "      <td>Entre Dos Aguas</td>\n",
       "      <td>Flamenco Para Niños</td>\n",
       "      <td>Paco De Lucia</td>\n",
       "      <td>1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54961</td>\n",
       "      <td>736</td>\n",
       "      <td>1</td>\n",
       "      <td>Stronger</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Kanye West</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54961</td>\n",
       "      <td>750</td>\n",
       "      <td>1</td>\n",
       "      <td>Constellations</td>\n",
       "      <td>In Between Dreams</td>\n",
       "      <td>Jack Johnson</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54961</td>\n",
       "      <td>1188</td>\n",
       "      <td>1</td>\n",
       "      <td>Learn To Fly</td>\n",
       "      <td>There Is Nothing Left To Lose</td>\n",
       "      <td>Foo Fighters</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  song_id  play_count            title  \\\n",
       "0    54961      153           1         The Cove   \n",
       "1    54961      413           2  Entre Dos Aguas   \n",
       "2    54961      736           1         Stronger   \n",
       "3    54961      750           1   Constellations   \n",
       "4    54961     1188           1     Learn To Fly   \n",
       "\n",
       "                         release    artist_name  year  \n",
       "0             Thicker Than Water   Jack Johnson     0  \n",
       "1            Flamenco Para Niños  Paco De Lucia  1976  \n",
       "2                     Graduation     Kanye West  2007  \n",
       "3              In Between Dreams   Jack Johnson  2005  \n",
       "4  There Is Nothing Left To Lose   Foo Fighters  1999  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using label encoding in song_id and user_id to ease our processing of the dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['user_id'] = le.fit_transform(df['user_id'])\n",
    "df['song_id'] = le.fit_transform(df['song_id'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As this dataset is very large and has 2000000 observations, it is not computationally possible to build a model using this. Moreover, many users have only listened a few songs and also some songs are heard by very few users. Hence we can reduce the dataset by considering certain Logical assumptions.**\n",
    "\n",
    "Here, we will be taking users who have listened at least 90 songs, and the songs that are listened by at least 120 users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get column containing the users\n",
    "users = df.user_id\n",
    "# create a dictionary from users to their number of songs\n",
    "ratings_count = {}\n",
    "# adding users to the dictionary\n",
    "for user in users:\n",
    "    # if the user is already in the dict, just add 1 to their rating count\n",
    "    if user in ratings_count:\n",
    "        ratings_count[user] += 1\n",
    "    # if not, set their rating count to 1\n",
    "    else:\n",
    "        ratings_count[user] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{54961: 45,\n",
       " 39877: 1,\n",
       " 56522: 8,\n",
       " 40874: 2,\n",
       " 45012: 19,\n",
       " 22570: 13,\n",
       " 66678: 25,\n",
       " 47087: 11,\n",
       " 46575: 6,\n",
       " 54498: 66,\n",
       " 6958: 103,\n",
       " 63855: 52,\n",
       " 27018: 401,\n",
       " 59353: 6,\n",
       " 20639: 4,\n",
       " 70730: 2,\n",
       " 55837: 100,\n",
       " 6647: 32,\n",
       " 50286: 6,\n",
       " 56576: 118,\n",
       " 3204: 20,\n",
       " 38632: 3,\n",
       " 19147: 15,\n",
       " 74048: 22,\n",
       " 48241: 9,\n",
       " 19194: 20,\n",
       " 13178: 28,\n",
       " 42347: 12,\n",
       " 57055: 7,\n",
       " 5416: 18,\n",
       " 49549: 153,\n",
       " 44537: 13,\n",
       " 12898: 22,\n",
       " 58003: 1,\n",
       " 18808: 65,\n",
       " 43278: 15,\n",
       " 70892: 35,\n",
       " 73298: 15,\n",
       " 9415: 5,\n",
       " 21487: 52,\n",
       " 76143: 10,\n",
       " 63872: 24,\n",
       " 359: 23,\n",
       " 24533: 19,\n",
       " 20082: 17,\n",
       " 43942: 57,\n",
       " 34420: 11,\n",
       " 60317: 44,\n",
       " 53867: 6,\n",
       " 12635: 32,\n",
       " 33130: 7,\n",
       " 68660: 11,\n",
       " 45949: 20,\n",
       " 35629: 38,\n",
       " 49202: 16,\n",
       " 54615: 62,\n",
       " 49608: 4,\n",
       " 38327: 9,\n",
       " 45988: 19,\n",
       " 70816: 27,\n",
       " 75935: 6,\n",
       " 34234: 156,\n",
       " 3540: 5,\n",
       " 18971: 45,\n",
       " 7798: 56,\n",
       " 49235: 7,\n",
       " 72300: 23,\n",
       " 65206: 12,\n",
       " 22784: 4,\n",
       " 41940: 35,\n",
       " 17679: 25,\n",
       " 58071: 7,\n",
       " 384: 63,\n",
       " 47801: 61,\n",
       " 29430: 11,\n",
       " 7952: 3,\n",
       " 54091: 16,\n",
       " 72841: 8,\n",
       " 9670: 32,\n",
       " 37560: 64,\n",
       " 69683: 47,\n",
       " 6937: 12,\n",
       " 54439: 103,\n",
       " 35957: 10,\n",
       " 19076: 58,\n",
       " 44618: 26,\n",
       " 2282: 52,\n",
       " 38800: 5,\n",
       " 26436: 8,\n",
       " 54164: 6,\n",
       " 6285: 37,\n",
       " 30346: 12,\n",
       " 25492: 6,\n",
       " 44689: 97,\n",
       " 15550: 45,\n",
       " 14046: 39,\n",
       " 47803: 32,\n",
       " 70178: 18,\n",
       " 25651: 20,\n",
       " 70000: 54,\n",
       " 52925: 29,\n",
       " 44648: 29,\n",
       " 22447: 13,\n",
       " 6872: 8,\n",
       " 42650: 25,\n",
       " 37000: 4,\n",
       " 24267: 20,\n",
       " 53923: 56,\n",
       " 56544: 58,\n",
       " 21274: 18,\n",
       " 40553: 7,\n",
       " 39887: 11,\n",
       " 27881: 43,\n",
       " 68345: 18,\n",
       " 58076: 21,\n",
       " 19568: 24,\n",
       " 6888: 6,\n",
       " 4351: 2,\n",
       " 70647: 8,\n",
       " 17831: 16,\n",
       " 40583: 191,\n",
       " 64176: 16,\n",
       " 40543: 8,\n",
       " 46525: 170,\n",
       " 17192: 8,\n",
       " 49395: 28,\n",
       " 55758: 45,\n",
       " 37086: 13,\n",
       " 68099: 6,\n",
       " 42302: 93,\n",
       " 24524: 9,\n",
       " 28077: 8,\n",
       " 68048: 48,\n",
       " 41638: 10,\n",
       " 7320: 131,\n",
       " 75095: 12,\n",
       " 57655: 6,\n",
       " 69800: 9,\n",
       " 4383: 18,\n",
       " 10723: 44,\n",
       " 66723: 18,\n",
       " 12383: 3,\n",
       " 39814: 159,\n",
       " 10374: 10,\n",
       " 69499: 5,\n",
       " 56100: 6,\n",
       " 35178: 12,\n",
       " 25875: 18,\n",
       " 1957: 2,\n",
       " 69331: 10,\n",
       " 11205: 34,\n",
       " 6962: 6,\n",
       " 67308: 139,\n",
       " 1106: 2,\n",
       " 54985: 3,\n",
       " 66587: 17,\n",
       " 70769: 19,\n",
       " 37218: 20,\n",
       " 73336: 32,\n",
       " 14733: 27,\n",
       " 24905: 20,\n",
       " 21914: 8,\n",
       " 21022: 52,\n",
       " 5364: 53,\n",
       " 76260: 23,\n",
       " 31007: 8,\n",
       " 31739: 8,\n",
       " 54038: 3,\n",
       " 10626: 6,\n",
       " 16375: 37,\n",
       " 5480: 113,\n",
       " 45100: 7,\n",
       " 41920: 25,\n",
       " 8074: 151,\n",
       " 70127: 6,\n",
       " 49462: 13,\n",
       " 46974: 28,\n",
       " 67544: 15,\n",
       " 52602: 20,\n",
       " 7580: 9,\n",
       " 13742: 18,\n",
       " 44630: 21,\n",
       " 23039: 27,\n",
       " 15529: 16,\n",
       " 74957: 20,\n",
       " 65917: 1,\n",
       " 29269: 14,\n",
       " 42736: 6,\n",
       " 38260: 50,\n",
       " 51929: 77,\n",
       " 21723: 6,\n",
       " 45910: 26,\n",
       " 58637: 11,\n",
       " 20336: 14,\n",
       " 44165: 14,\n",
       " 62889: 8,\n",
       " 46036: 14,\n",
       " 57842: 14,\n",
       " 19069: 26,\n",
       " 68752: 17,\n",
       " 61220: 10,\n",
       " 28120: 13,\n",
       " 56716: 88,\n",
       " 68474: 4,\n",
       " 67003: 10,\n",
       " 53778: 14,\n",
       " 37800: 8,\n",
       " 4221: 1,\n",
       " 71509: 17,\n",
       " 35744: 15,\n",
       " 57332: 21,\n",
       " 71948: 6,\n",
       " 55381: 10,\n",
       " 37453: 35,\n",
       " 5106: 41,\n",
       " 64929: 9,\n",
       " 59211: 27,\n",
       " 24735: 46,\n",
       " 58257: 10,\n",
       " 42949: 42,\n",
       " 12207: 7,\n",
       " 60893: 26,\n",
       " 31951: 18,\n",
       " 67704: 127,\n",
       " 52915: 9,\n",
       " 63309: 10,\n",
       " 45974: 8,\n",
       " 22571: 10,\n",
       " 24049: 7,\n",
       " 70205: 10,\n",
       " 2930: 27,\n",
       " 56359: 15,\n",
       " 46710: 11,\n",
       " 19680: 40,\n",
       " 69790: 15,\n",
       " 27069: 10,\n",
       " 16796: 27,\n",
       " 24651: 55,\n",
       " 63590: 28,\n",
       " 65943: 12,\n",
       " 49832: 24,\n",
       " 28913: 30,\n",
       " 3571: 18,\n",
       " 30503: 16,\n",
       " 24889: 24,\n",
       " 36997: 17,\n",
       " 7759: 9,\n",
       " 24111: 14,\n",
       " 12026: 27,\n",
       " 74600: 8,\n",
       " 61684: 5,\n",
       " 37380: 3,\n",
       " 67139: 36,\n",
       " 44449: 97,\n",
       " 35057: 11,\n",
       " 32798: 11,\n",
       " 19107: 2,\n",
       " 31193: 3,\n",
       " 19814: 17,\n",
       " 47024: 6,\n",
       " 21859: 16,\n",
       " 70354: 84,\n",
       " 24978: 11,\n",
       " 31691: 3,\n",
       " 27042: 17,\n",
       " 25062: 11,\n",
       " 65657: 21,\n",
       " 67545: 3,\n",
       " 42056: 14,\n",
       " 6555: 17,\n",
       " 19022: 17,\n",
       " 71814: 42,\n",
       " 17033: 73,\n",
       " 67884: 12,\n",
       " 75358: 10,\n",
       " 6875: 20,\n",
       " 68028: 10,\n",
       " 1576: 7,\n",
       " 44723: 15,\n",
       " 71505: 23,\n",
       " 29278: 9,\n",
       " 46762: 70,\n",
       " 66062: 44,\n",
       " 2931: 15,\n",
       " 16962: 5,\n",
       " 22540: 47,\n",
       " 19916: 27,\n",
       " 22815: 21,\n",
       " 26967: 4,\n",
       " 13485: 9,\n",
       " 32958: 21,\n",
       " 45354: 44,\n",
       " 69741: 19,\n",
       " 35736: 15,\n",
       " 29819: 25,\n",
       " 23627: 10,\n",
       " 6056: 3,\n",
       " 75901: 108,\n",
       " 5683: 14,\n",
       " 30576: 31,\n",
       " 17278: 5,\n",
       " 24213: 21,\n",
       " 11130: 25,\n",
       " 65909: 37,\n",
       " 9824: 9,\n",
       " 41720: 16,\n",
       " 68747: 18,\n",
       " 25374: 7,\n",
       " 33165: 13,\n",
       " 69827: 12,\n",
       " 73575: 7,\n",
       " 73475: 30,\n",
       " 31938: 9,\n",
       " 12223: 19,\n",
       " 75569: 21,\n",
       " 13133: 3,\n",
       " 57932: 169,\n",
       " 68134: 6,\n",
       " 16374: 21,\n",
       " 49514: 13,\n",
       " 52163: 12,\n",
       " 14759: 14,\n",
       " 30697: 14,\n",
       " 75100: 9,\n",
       " 4037: 50,\n",
       " 35564: 3,\n",
       " 66788: 31,\n",
       " 39566: 7,\n",
       " 19035: 46,\n",
       " 60626: 21,\n",
       " 69675: 11,\n",
       " 10768: 7,\n",
       " 32094: 47,\n",
       " 15324: 15,\n",
       " 17000: 1,\n",
       " 50337: 5,\n",
       " 8115: 36,\n",
       " 10275: 58,\n",
       " 7699: 5,\n",
       " 4710: 13,\n",
       " 42893: 24,\n",
       " 22888: 7,\n",
       " 47116: 15,\n",
       " 45386: 132,\n",
       " 26205: 43,\n",
       " 41666: 32,\n",
       " 43040: 57,\n",
       " 18642: 10,\n",
       " 28101: 5,\n",
       " 58921: 15,\n",
       " 20864: 18,\n",
       " 15219: 30,\n",
       " 52928: 131,\n",
       " 22429: 18,\n",
       " 50294: 31,\n",
       " 54103: 28,\n",
       " 58939: 41,\n",
       " 57705: 12,\n",
       " 23431: 15,\n",
       " 8815: 14,\n",
       " 55281: 1,\n",
       " 55704: 7,\n",
       " 57006: 24,\n",
       " 2544: 7,\n",
       " 6432: 8,\n",
       " 3679: 12,\n",
       " 59302: 8,\n",
       " 62934: 26,\n",
       " 2570: 31,\n",
       " 55789: 4,\n",
       " 37818: 22,\n",
       " 35281: 8,\n",
       " 57909: 12,\n",
       " 12919: 24,\n",
       " 60532: 4,\n",
       " 3833: 18,\n",
       " 45705: 59,\n",
       " 50430: 8,\n",
       " 69860: 15,\n",
       " 59919: 16,\n",
       " 22960: 12,\n",
       " 59443: 15,\n",
       " 70318: 129,\n",
       " 26064: 25,\n",
       " 63215: 33,\n",
       " 19348: 42,\n",
       " 60795: 7,\n",
       " 8077: 51,\n",
       " 20380: 20,\n",
       " 16955: 17,\n",
       " 18966: 46,\n",
       " 74279: 117,\n",
       " 22279: 16,\n",
       " 49179: 12,\n",
       " 4218: 72,\n",
       " 16353: 55,\n",
       " 35867: 39,\n",
       " 66173: 30,\n",
       " 41899: 11,\n",
       " 16935: 7,\n",
       " 69190: 36,\n",
       " 24546: 6,\n",
       " 58291: 41,\n",
       " 12059: 6,\n",
       " 43715: 19,\n",
       " 16233: 9,\n",
       " 11128: 7,\n",
       " 71716: 13,\n",
       " 75000: 16,\n",
       " 35296: 24,\n",
       " 21129: 5,\n",
       " 12437: 5,\n",
       " 49: 37,\n",
       " 51271: 18,\n",
       " 13190: 21,\n",
       " 30955: 21,\n",
       " 35457: 124,\n",
       " 64338: 11,\n",
       " 1114: 20,\n",
       " 75482: 71,\n",
       " 64871: 69,\n",
       " 34187: 16,\n",
       " 74938: 22,\n",
       " 43123: 43,\n",
       " 54935: 11,\n",
       " 54627: 10,\n",
       " 16058: 12,\n",
       " 8808: 8,\n",
       " 48108: 6,\n",
       " 33848: 8,\n",
       " 48883: 46,\n",
       " 53950: 5,\n",
       " 19617: 6,\n",
       " 38857: 9,\n",
       " 7310: 6,\n",
       " 31810: 46,\n",
       " 46478: 53,\n",
       " 23600: 5,\n",
       " 4130: 33,\n",
       " 30950: 23,\n",
       " 65509: 10,\n",
       " 61927: 19,\n",
       " 24185: 2,\n",
       " 66308: 34,\n",
       " 41758: 11,\n",
       " 72966: 14,\n",
       " 8208: 21,\n",
       " 16716: 19,\n",
       " 37381: 11,\n",
       " 45480: 42,\n",
       " 16292: 22,\n",
       " 68364: 12,\n",
       " 15860: 10,\n",
       " 24375: 20,\n",
       " 2477: 22,\n",
       " 58797: 11,\n",
       " 70811: 138,\n",
       " 34074: 19,\n",
       " 24782: 67,\n",
       " 16914: 68,\n",
       " 34225: 93,\n",
       " 29301: 8,\n",
       " 46427: 24,\n",
       " 27948: 6,\n",
       " 41985: 86,\n",
       " 57343: 12,\n",
       " 18199: 34,\n",
       " 54337: 3,\n",
       " 33304: 20,\n",
       " 59763: 10,\n",
       " 67816: 13,\n",
       " 6705: 84,\n",
       " 37753: 9,\n",
       " 54419: 23,\n",
       " 37055: 42,\n",
       " 25107: 37,\n",
       " 53444: 5,\n",
       " 38728: 51,\n",
       " 66796: 31,\n",
       " 7644: 26,\n",
       " 68619: 26,\n",
       " 74773: 6,\n",
       " 40201: 9,\n",
       " 23445: 32,\n",
       " 18318: 2,\n",
       " 41515: 14,\n",
       " 58775: 14,\n",
       " 994: 7,\n",
       " 31416: 66,\n",
       " 14393: 18,\n",
       " 1656: 20,\n",
       " 61580: 8,\n",
       " 25510: 8,\n",
       " 27537: 20,\n",
       " 48420: 21,\n",
       " 10004: 9,\n",
       " 66488: 7,\n",
       " 50338: 39,\n",
       " 16585: 52,\n",
       " 24158: 35,\n",
       " 22749: 123,\n",
       " 31103: 9,\n",
       " 59140: 14,\n",
       " 59195: 15,\n",
       " 62274: 16,\n",
       " 54982: 10,\n",
       " 43963: 10,\n",
       " 57479: 10,\n",
       " 32912: 12,\n",
       " 15852: 12,\n",
       " 55412: 16,\n",
       " 53619: 6,\n",
       " 8884: 10,\n",
       " 21773: 36,\n",
       " 58679: 4,\n",
       " 69421: 4,\n",
       " 57604: 8,\n",
       " 4948: 33,\n",
       " 46808: 13,\n",
       " 22524: 20,\n",
       " 18385: 3,\n",
       " 16771: 12,\n",
       " 48294: 1,\n",
       " 11856: 4,\n",
       " 3377: 28,\n",
       " 5672: 39,\n",
       " 61159: 46,\n",
       " 6749: 33,\n",
       " 38579: 68,\n",
       " 69587: 126,\n",
       " 8529: 21,\n",
       " 25850: 71,\n",
       " 3822: 4,\n",
       " 18162: 13,\n",
       " 69183: 18,\n",
       " 12268: 21,\n",
       " 62871: 21,\n",
       " 2828: 8,\n",
       " 20224: 17,\n",
       " 63134: 52,\n",
       " 30666: 38,\n",
       " 36731: 4,\n",
       " 3216: 36,\n",
       " 57000: 23,\n",
       " 53971: 16,\n",
       " 33102: 4,\n",
       " 6961: 4,\n",
       " 60910: 171,\n",
       " 47304: 30,\n",
       " 54949: 15,\n",
       " 23560: 9,\n",
       " 54146: 4,\n",
       " 39303: 45,\n",
       " 75288: 31,\n",
       " 3001: 8,\n",
       " 55637: 9,\n",
       " 55070: 13,\n",
       " 64200: 36,\n",
       " 23335: 20,\n",
       " 39206: 37,\n",
       " 34403: 19,\n",
       " 63816: 4,\n",
       " 11065: 58,\n",
       " 45081: 5,\n",
       " 65007: 56,\n",
       " 46383: 9,\n",
       " 47900: 28,\n",
       " 5594: 4,\n",
       " 17455: 8,\n",
       " 70135: 21,\n",
       " 38796: 41,\n",
       " 56212: 21,\n",
       " 49056: 18,\n",
       " 65287: 11,\n",
       " 39908: 17,\n",
       " 46679: 42,\n",
       " 51559: 7,\n",
       " 51415: 132,\n",
       " 18379: 8,\n",
       " 61316: 7,\n",
       " 32714: 26,\n",
       " 63035: 43,\n",
       " 73724: 4,\n",
       " 44438: 12,\n",
       " 54413: 11,\n",
       " 49509: 49,\n",
       " 64603: 5,\n",
       " 47091: 3,\n",
       " 41419: 12,\n",
       " 63817: 25,\n",
       " 41035: 10,\n",
       " 24779: 12,\n",
       " 11656: 9,\n",
       " 66174: 16,\n",
       " 48616: 3,\n",
       " 36577: 8,\n",
       " 2146: 7,\n",
       " 74145: 43,\n",
       " 42536: 206,\n",
       " 37938: 100,\n",
       " 67333: 9,\n",
       " 63011: 13,\n",
       " 63000: 17,\n",
       " 21348: 9,\n",
       " 39382: 9,\n",
       " 57898: 8,\n",
       " 41556: 9,\n",
       " 41000: 27,\n",
       " 39758: 4,\n",
       " 53607: 8,\n",
       " 23749: 15,\n",
       " 6401: 11,\n",
       " 36864: 79,\n",
       " 439: 51,\n",
       " 57329: 5,\n",
       " 65290: 24,\n",
       " 48869: 34,\n",
       " 44195: 1,\n",
       " 53918: 17,\n",
       " 12642: 52,\n",
       " 36708: 38,\n",
       " 76020: 28,\n",
       " 15641: 13,\n",
       " 56192: 17,\n",
       " 53451: 30,\n",
       " 15470: 15,\n",
       " 46832: 27,\n",
       " 75113: 12,\n",
       " 30936: 16,\n",
       " 10586: 8,\n",
       " 22751: 8,\n",
       " 16695: 12,\n",
       " 66525: 3,\n",
       " 27862: 40,\n",
       " 4332: 22,\n",
       " 32896: 18,\n",
       " 13917: 21,\n",
       " 21199: 8,\n",
       " 29399: 18,\n",
       " 23612: 22,\n",
       " 21865: 8,\n",
       " 39901: 93,\n",
       " 52226: 12,\n",
       " 42709: 72,\n",
       " 4506: 6,\n",
       " 52919: 6,\n",
       " 38468: 5,\n",
       " 1850: 20,\n",
       " 12602: 44,\n",
       " 51984: 11,\n",
       " 25306: 10,\n",
       " 63769: 25,\n",
       " 68170: 10,\n",
       " 35388: 9,\n",
       " 45286: 8,\n",
       " 68081: 22,\n",
       " 36785: 26,\n",
       " 66720: 9,\n",
       " 17441: 15,\n",
       " 64928: 26,\n",
       " 29738: 20,\n",
       " 16033: 17,\n",
       " 67677: 21,\n",
       " 49447: 59,\n",
       " 73203: 17,\n",
       " 68499: 9,\n",
       " 40549: 123,\n",
       " 66943: 25,\n",
       " 58760: 6,\n",
       " 34575: 28,\n",
       " 14734: 9,\n",
       " 12007: 10,\n",
       " 61524: 15,\n",
       " 11546: 29,\n",
       " 72806: 7,\n",
       " 32716: 19,\n",
       " 40199: 25,\n",
       " 20151: 21,\n",
       " 21413: 20,\n",
       " 43178: 14,\n",
       " 43992: 39,\n",
       " 25185: 17,\n",
       " 9598: 9,\n",
       " 61371: 1,\n",
       " 61457: 16,\n",
       " 45224: 21,\n",
       " 59566: 14,\n",
       " 12527: 3,\n",
       " 1822: 54,\n",
       " 42192: 6,\n",
       " 56823: 8,\n",
       " 34981: 27,\n",
       " 55114: 11,\n",
       " 53666: 64,\n",
       " 46403: 26,\n",
       " 33810: 8,\n",
       " 4: 9,\n",
       " 70652: 10,\n",
       " 27591: 19,\n",
       " 72958: 14,\n",
       " 35264: 11,\n",
       " 7496: 12,\n",
       " 29761: 19,\n",
       " 70608: 64,\n",
       " 26275: 42,\n",
       " 8569: 46,\n",
       " 32285: 39,\n",
       " 12273: 12,\n",
       " 3734: 8,\n",
       " 56644: 7,\n",
       " 56904: 71,\n",
       " 67461: 42,\n",
       " 51267: 7,\n",
       " 56006: 22,\n",
       " 60010: 20,\n",
       " 33786: 15,\n",
       " 64330: 15,\n",
       " 39738: 20,\n",
       " 50904: 6,\n",
       " 5730: 22,\n",
       " 29111: 65,\n",
       " 37056: 74,\n",
       " 76100: 37,\n",
       " 8760: 21,\n",
       " 33323: 44,\n",
       " 21128: 1,\n",
       " 65661: 32,\n",
       " 46303: 72,\n",
       " 7278: 6,\n",
       " 36696: 20,\n",
       " 49974: 19,\n",
       " 2217: 6,\n",
       " 60510: 11,\n",
       " 26157: 53,\n",
       " 58971: 16,\n",
       " 12480: 38,\n",
       " 51443: 11,\n",
       " 34445: 91,\n",
       " 12671: 6,\n",
       " 44895: 17,\n",
       " 62654: 13,\n",
       " 63558: 5,\n",
       " 21577: 9,\n",
       " 16297: 9,\n",
       " 47462: 10,\n",
       " 27483: 6,\n",
       " 35142: 14,\n",
       " 3208: 16,\n",
       " 14806: 7,\n",
       " 18256: 43,\n",
       " 67222: 11,\n",
       " 6099: 17,\n",
       " 60060: 6,\n",
       " 40930: 32,\n",
       " 39469: 9,\n",
       " 9097: 364,\n",
       " 28166: 8,\n",
       " 32510: 18,\n",
       " 19351: 27,\n",
       " 40666: 23,\n",
       " 36342: 9,\n",
       " 51379: 7,\n",
       " 17590: 10,\n",
       " 8425: 29,\n",
       " 17459: 7,\n",
       " 17789: 55,\n",
       " 64429: 87,\n",
       " 70999: 37,\n",
       " 71513: 17,\n",
       " 66038: 37,\n",
       " 65975: 17,\n",
       " 56567: 9,\n",
       " 57965: 8,\n",
       " 41042: 7,\n",
       " 26028: 22,\n",
       " 19056: 1,\n",
       " 15627: 13,\n",
       " 54977: 23,\n",
       " 60631: 15,\n",
       " 47968: 2,\n",
       " 28347: 35,\n",
       " 22308: 12,\n",
       " 55669: 7,\n",
       " 20912: 13,\n",
       " 73319: 13,\n",
       " 7914: 11,\n",
       " 34418: 13,\n",
       " 44263: 12,\n",
       " 74241: 30,\n",
       " 16646: 7,\n",
       " 48914: 30,\n",
       " 65160: 54,\n",
       " 778: 13,\n",
       " 61548: 32,\n",
       " 15009: 30,\n",
       " 54053: 11,\n",
       " 27199: 30,\n",
       " 19193: 187,\n",
       " 29320: 41,\n",
       " 52764: 15,\n",
       " 42812: 16,\n",
       " 15163: 37,\n",
       " 56246: 38,\n",
       " 38559: 8,\n",
       " 38558: 7,\n",
       " 29809: 7,\n",
       " 23147: 12,\n",
       " 64407: 7,\n",
       " 8761: 36,\n",
       " 21958: 3,\n",
       " 2030: 5,\n",
       " 73372: 11,\n",
       " 64624: 72,\n",
       " 40104: 34,\n",
       " 17371: 34,\n",
       " 39612: 28,\n",
       " 59121: 31,\n",
       " 6475: 19,\n",
       " 47033: 47,\n",
       " 54325: 40,\n",
       " 33256: 4,\n",
       " 63415: 7,\n",
       " 35091: 222,\n",
       " 55629: 6,\n",
       " 37708: 12,\n",
       " 21001: 20,\n",
       " 45359: 25,\n",
       " 29249: 14,\n",
       " 33201: 35,\n",
       " 31324: 73,\n",
       " 8616: 6,\n",
       " 71890: 37,\n",
       " 74334: 245,\n",
       " 36487: 9,\n",
       " 6073: 85,\n",
       " 72697: 14,\n",
       " 1624: 28,\n",
       " 38125: 16,\n",
       " 4145: 8,\n",
       " 21882: 10,\n",
       " 12329: 3,\n",
       " 16538: 27,\n",
       " 38709: 16,\n",
       " 29504: 42,\n",
       " 4522: 150,\n",
       " 4863: 23,\n",
       " 19447: 7,\n",
       " 33546: 27,\n",
       " 23117: 13,\n",
       " 73557: 39,\n",
       " 49763: 17,\n",
       " 55555: 17,\n",
       " 23754: 6,\n",
       " 16972: 6,\n",
       " 25883: 42,\n",
       " 37389: 10,\n",
       " 19964: 44,\n",
       " 2205: 4,\n",
       " 16708: 10,\n",
       " 161: 43,\n",
       " 33926: 11,\n",
       " 18852: 6,\n",
       " 55887: 8,\n",
       " 23753: 30,\n",
       " 32333: 10,\n",
       " 60986: 66,\n",
       " 20935: 5,\n",
       " 19646: 65,\n",
       " 15749: 13,\n",
       " 75666: 4,\n",
       " 24514: 8,\n",
       " 14607: 43,\n",
       " 38370: 81,\n",
       " 39934: 112,\n",
       " 33298: 22,\n",
       " 5283: 5,\n",
       " 46454: 19,\n",
       " 74828: 14,\n",
       " 42686: 34,\n",
       " 58980: 48,\n",
       " 48643: 13,\n",
       " 19098: 8,\n",
       " 55106: 46,\n",
       " 23297: 556,\n",
       " 4335: 19,\n",
       " 2490: 17,\n",
       " 18860: 13,\n",
       " 62507: 61,\n",
       " 54896: 49,\n",
       " 70976: 24,\n",
       " 40127: 14,\n",
       " 47209: 36,\n",
       " 65275: 10,\n",
       " 66949: 27,\n",
       " 59374: 8,\n",
       " 62016: 11,\n",
       " 3820: 48,\n",
       " 29286: 33,\n",
       " 7731: 59,\n",
       " 46788: 25,\n",
       " 71289: 57,\n",
       " 33273: 6,\n",
       " 13416: 40,\n",
       " 26316: 3,\n",
       " 34496: 17,\n",
       " 4273: 8,\n",
       " 57675: 25,\n",
       " 59281: 8,\n",
       " 3101: 12,\n",
       " 74435: 13,\n",
       " 2399: 94,\n",
       " 45999: 6,\n",
       " 47818: 17,\n",
       " 75292: 6,\n",
       " 28952: 9,\n",
       " 48331: 42,\n",
       " 46770: 6,\n",
       " 4238: 67,\n",
       " 52743: 15,\n",
       " 31800: 20,\n",
       " 49711: 9,\n",
       " 74688: 57,\n",
       " 60166: 9,\n",
       " 27369: 10,\n",
       " 12085: 11,\n",
       " 52684: 42,\n",
       " 60835: 39,\n",
       " 51720: 57,\n",
       " 10795: 15,\n",
       " 15245: 9,\n",
       " 68200: 14,\n",
       " 33037: 6,\n",
       " 70985: 2,\n",
       " 27850: 12,\n",
       " 60757: 14,\n",
       " 54567: 8,\n",
       " 70344: 21,\n",
       " 34492: 71,\n",
       " 70418: 11,\n",
       " 75276: 22,\n",
       " 56798: 58,\n",
       " 6537: 19,\n",
       " 8928: 16,\n",
       " 33058: 49,\n",
       " 23764: 18,\n",
       " 50168: 9,\n",
       " 63809: 30,\n",
       " 74128: 29,\n",
       " 74508: 16,\n",
       " 31138: 3,\n",
       " 42798: 39,\n",
       " 18135: 9,\n",
       " 56876: 14,\n",
       " 43491: 18,\n",
       " 38019: 16,\n",
       " 27871: 79,\n",
       " 29229: 15,\n",
       " 52003: 10,\n",
       " 60596: 1,\n",
       " 20537: 1,\n",
       " 1487: 31,\n",
       " 31880: 1,\n",
       " 12701: 57,\n",
       " 54216: 39,\n",
       " 67871: 64,\n",
       " 49333: 9,\n",
       " 38362: 141,\n",
       " 40391: 9,\n",
       " 74: 4,\n",
       " 3737: 8,\n",
       " 45079: 22,\n",
       " 72006: 13,\n",
       " 74015: 18,\n",
       " 26087: 4,\n",
       " 74698: 1,\n",
       " 53668: 19,\n",
       " 46999: 12,\n",
       " 33383: 10,\n",
       " 51402: 10,\n",
       " 49063: 9,\n",
       " 16942: 25,\n",
       " 67995: 24,\n",
       " 60550: 7,\n",
       " 19754: 12,\n",
       " 34497: 4,\n",
       " 61294: 11,\n",
       " 54065: 10,\n",
       " 51864: 15,\n",
       " 66575: 19,\n",
       " 62907: 13,\n",
       " 56921: 17,\n",
       " 71692: 54,\n",
       " 48521: 6,\n",
       " 13683: 10,\n",
       " 12564: 26,\n",
       " 9350: 59,\n",
       " 31601: 27,\n",
       " 7810: 6,\n",
       " 19612: 5,\n",
       " 71731: 14,\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438390, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only get users to have listened at least 90 different songs\n",
    "# list to keep the users that will be removed\n",
    "remove_users = []\n",
    "# iterating throut the dict\n",
    "for user, num_ratings in ratings_count.items():\n",
    "    if num_ratings < 90:\n",
    "        remove_users.append(user)\n",
    "\n",
    "# removing users from the dataframe\n",
    "df = df.loc[~df.user_id.isin(remove_users)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the column containing the songs\n",
    "songs = df.song_id\n",
    "# create a dict from songs to their number of listened times\n",
    "listened_count = {}\n",
    "# loop throut to songs\n",
    "for song in songs:\n",
    "    # if the song is already in the dict, just add 1 to the count\n",
    "    if song in listened_count:\n",
    "        listened_count[song] += 1\n",
    "    # else, set their count to 1\n",
    "    else:\n",
    "        listened_count[song] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{12: 32,\n",
       " 40: 59,\n",
       " 151: 88,\n",
       " 326: 96,\n",
       " 447: 143,\n",
       " 484: 100,\n",
       " 512: 241,\n",
       " 549: 156,\n",
       " 703: 628,\n",
       " 719: 144,\n",
       " 892: 174,\n",
       " 933: 54,\n",
       " 974: 64,\n",
       " 1050: 135,\n",
       " 1056: 109,\n",
       " 1357: 56,\n",
       " 1409: 61,\n",
       " 1480: 246,\n",
       " 1600: 103,\n",
       " 1671: 153,\n",
       " 1752: 169,\n",
       " 1756: 150,\n",
       " 1787: 282,\n",
       " 1818: 130,\n",
       " 1867: 33,\n",
       " 2107: 121,\n",
       " 2126: 30,\n",
       " 2168: 88,\n",
       " 2267: 54,\n",
       " 2289: 131,\n",
       " 2304: 159,\n",
       " 2425: 163,\n",
       " 2501: 121,\n",
       " 2542: 76,\n",
       " 2543: 62,\n",
       " 2555: 73,\n",
       " 2701: 135,\n",
       " 2719: 79,\n",
       " 2737: 106,\n",
       " 2898: 138,\n",
       " 2928: 85,\n",
       " 2994: 220,\n",
       " 3043: 98,\n",
       " 3074: 471,\n",
       " 3134: 115,\n",
       " 3144: 98,\n",
       " 3434: 87,\n",
       " 3447: 101,\n",
       " 3491: 128,\n",
       " 3524: 48,\n",
       " 3551: 145,\n",
       " 3718: 163,\n",
       " 3796: 52,\n",
       " 3801: 153,\n",
       " 3881: 92,\n",
       " 3907: 151,\n",
       " 3949: 104,\n",
       " 4061: 69,\n",
       " 4107: 72,\n",
       " 4229: 58,\n",
       " 4363: 92,\n",
       " 4469: 104,\n",
       " 4862: 116,\n",
       " 5003: 70,\n",
       " 5006: 96,\n",
       " 5073: 48,\n",
       " 5193: 167,\n",
       " 5326: 114,\n",
       " 5340: 121,\n",
       " 5343: 80,\n",
       " 5355: 101,\n",
       " 5441: 127,\n",
       " 5505: 53,\n",
       " 5566: 128,\n",
       " 5817: 42,\n",
       " 5894: 180,\n",
       " 6305: 162,\n",
       " 6323: 41,\n",
       " 6711: 56,\n",
       " 6870: 83,\n",
       " 7007: 94,\n",
       " 7050: 100,\n",
       " 7280: 70,\n",
       " 7344: 56,\n",
       " 7738: 159,\n",
       " 8029: 360,\n",
       " 8037: 246,\n",
       " 8230: 107,\n",
       " 8285: 70,\n",
       " 8406: 36,\n",
       " 8425: 172,\n",
       " 8525: 65,\n",
       " 8542: 88,\n",
       " 8873: 105,\n",
       " 9065: 122,\n",
       " 9124: 52,\n",
       " 9338: 75,\n",
       " 9351: 143,\n",
       " 9398: 22,\n",
       " 9451: 96,\n",
       " 9510: 69,\n",
       " 9780: 65,\n",
       " 9891: 75,\n",
       " 97: 411,\n",
       " 122: 123,\n",
       " 139: 133,\n",
       " 149: 56,\n",
       " 189: 108,\n",
       " 198: 190,\n",
       " 215: 45,\n",
       " 220: 18,\n",
       " 248: 134,\n",
       " 267: 114,\n",
       " 270: 62,\n",
       " 299: 100,\n",
       " 305: 101,\n",
       " 311: 30,\n",
       " 318: 132,\n",
       " 342: 55,\n",
       " 358: 75,\n",
       " 444: 49,\n",
       " 445: 39,\n",
       " 487: 67,\n",
       " 522: 43,\n",
       " 528: 74,\n",
       " 578: 85,\n",
       " 596: 46,\n",
       " 611: 71,\n",
       " 693: 122,\n",
       " 765: 150,\n",
       " 769: 86,\n",
       " 786: 194,\n",
       " 798: 19,\n",
       " 810: 73,\n",
       " 861: 142,\n",
       " 872: 62,\n",
       " 903: 32,\n",
       " 926: 182,\n",
       " 929: 47,\n",
       " 958: 82,\n",
       " 967: 91,\n",
       " 992: 32,\n",
       " 1011: 32,\n",
       " 1037: 74,\n",
       " 1041: 108,\n",
       " 1070: 111,\n",
       " 1076: 54,\n",
       " 1118: 724,\n",
       " 1146: 68,\n",
       " 1189: 20,\n",
       " 1205: 37,\n",
       " 1209: 74,\n",
       " 1246: 109,\n",
       " 1262: 239,\n",
       " 1361: 80,\n",
       " 1406: 123,\n",
       " 1419: 29,\n",
       " 1429: 70,\n",
       " 1449: 110,\n",
       " 1461: 124,\n",
       " 1472: 179,\n",
       " 1519: 127,\n",
       " 1531: 55,\n",
       " 1571: 123,\n",
       " 1585: 45,\n",
       " 1588: 33,\n",
       " 1625: 73,\n",
       " 1630: 34,\n",
       " 1661: 80,\n",
       " 1682: 148,\n",
       " 1696: 120,\n",
       " 1747: 44,\n",
       " 1811: 388,\n",
       " 1835: 40,\n",
       " 1839: 24,\n",
       " 1858: 99,\n",
       " 1868: 106,\n",
       " 1878: 105,\n",
       " 1897: 57,\n",
       " 1907: 155,\n",
       " 1909: 77,\n",
       " 1914: 27,\n",
       " 1936: 189,\n",
       " 1942: 29,\n",
       " 1983: 150,\n",
       " 1995: 29,\n",
       " 2034: 33,\n",
       " 2054: 118,\n",
       " 2086: 35,\n",
       " 2106: 65,\n",
       " 2187: 198,\n",
       " 2234: 167,\n",
       " 2247: 84,\n",
       " 2297: 91,\n",
       " 2329: 74,\n",
       " 2389: 125,\n",
       " 2427: 72,\n",
       " 2435: 61,\n",
       " 2450: 81,\n",
       " 2502: 64,\n",
       " 2531: 110,\n",
       " 2550: 94,\n",
       " 2557: 139,\n",
       " 2601: 58,\n",
       " 2615: 157,\n",
       " 2630: 51,\n",
       " 2695: 118,\n",
       " 2747: 202,\n",
       " 2779: 56,\n",
       " 2784: 95,\n",
       " 2794: 111,\n",
       " 2808: 55,\n",
       " 2816: 62,\n",
       " 2824: 43,\n",
       " 2835: 46,\n",
       " 2858: 81,\n",
       " 2903: 84,\n",
       " 2962: 30,\n",
       " 3003: 195,\n",
       " 3106: 108,\n",
       " 3108: 112,\n",
       " 3111: 86,\n",
       " 3143: 58,\n",
       " 3168: 227,\n",
       " 3232: 148,\n",
       " 3252: 101,\n",
       " 3266: 22,\n",
       " 3324: 102,\n",
       " 3327: 70,\n",
       " 3356: 262,\n",
       " 3358: 105,\n",
       " 3388: 36,\n",
       " 3419: 35,\n",
       " 3440: 108,\n",
       " 3505: 42,\n",
       " 3510: 72,\n",
       " 3518: 166,\n",
       " 3548: 182,\n",
       " 3550: 47,\n",
       " 3574: 98,\n",
       " 3579: 105,\n",
       " 3632: 81,\n",
       " 3651: 81,\n",
       " 3655: 150,\n",
       " 3699: 191,\n",
       " 3702: 81,\n",
       " 3712: 107,\n",
       " 3740: 104,\n",
       " 3867: 91,\n",
       " 3882: 96,\n",
       " 3919: 72,\n",
       " 3936: 76,\n",
       " 4054: 51,\n",
       " 4081: 67,\n",
       " 4152: 721,\n",
       " 4195: 116,\n",
       " 4232: 123,\n",
       " 4261: 78,\n",
       " 4262: 202,\n",
       " 4281: 62,\n",
       " 4297: 40,\n",
       " 4298: 142,\n",
       " 4300: 64,\n",
       " 4336: 84,\n",
       " 4347: 75,\n",
       " 4349: 74,\n",
       " 4365: 29,\n",
       " 4371: 234,\n",
       " 4377: 174,\n",
       " 4455: 73,\n",
       " 4464: 83,\n",
       " 4510: 126,\n",
       " 4522: 206,\n",
       " 4545: 132,\n",
       " 4578: 62,\n",
       " 4598: 113,\n",
       " 4620: 57,\n",
       " 4626: 58,\n",
       " 4653: 122,\n",
       " 4691: 36,\n",
       " 4696: 33,\n",
       " 4700: 36,\n",
       " 4701: 87,\n",
       " 4720: 70,\n",
       " 4724: 123,\n",
       " 4792: 35,\n",
       " 4854: 36,\n",
       " 4878: 76,\n",
       " 4900: 107,\n",
       " 4937: 49,\n",
       " 4954: 228,\n",
       " 4960: 85,\n",
       " 4992: 64,\n",
       " 5019: 63,\n",
       " 5023: 356,\n",
       " 5030: 47,\n",
       " 5049: 126,\n",
       " 5058: 78,\n",
       " 5081: 63,\n",
       " 5082: 100,\n",
       " 5086: 48,\n",
       " 5112: 82,\n",
       " 5158: 138,\n",
       " 5222: 93,\n",
       " 5223: 129,\n",
       " 5224: 75,\n",
       " 5248: 151,\n",
       " 5287: 168,\n",
       " 5305: 161,\n",
       " 5345: 126,\n",
       " 5417: 140,\n",
       " 5422: 92,\n",
       " 5439: 64,\n",
       " 5457: 134,\n",
       " 5488: 55,\n",
       " 5548: 38,\n",
       " 5586: 68,\n",
       " 5593: 48,\n",
       " 5612: 63,\n",
       " 5665: 84,\n",
       " 5680: 82,\n",
       " 5752: 29,\n",
       " 5780: 75,\n",
       " 5804: 83,\n",
       " 5826: 152,\n",
       " 5858: 72,\n",
       " 5877: 167,\n",
       " 5919: 53,\n",
       " 5931: 73,\n",
       " 5962: 89,\n",
       " 5999: 142,\n",
       " 6071: 82,\n",
       " 6079: 160,\n",
       " 6103: 225,\n",
       " 6121: 120,\n",
       " 6148: 122,\n",
       " 6150: 37,\n",
       " 6153: 96,\n",
       " 6171: 79,\n",
       " 6174: 78,\n",
       " 6185: 68,\n",
       " 6191: 150,\n",
       " 6197: 65,\n",
       " 6203: 37,\n",
       " 6212: 88,\n",
       " 6232: 147,\n",
       " 6258: 82,\n",
       " 6293: 643,\n",
       " 6311: 32,\n",
       " 6343: 42,\n",
       " 6350: 128,\n",
       " 6355: 118,\n",
       " 6413: 13,\n",
       " 6459: 86,\n",
       " 6473: 85,\n",
       " 6482: 122,\n",
       " 6497: 110,\n",
       " 6500: 149,\n",
       " 6514: 73,\n",
       " 6538: 114,\n",
       " 6551: 38,\n",
       " 6566: 88,\n",
       " 6572: 126,\n",
       " 6607: 104,\n",
       " 6618: 157,\n",
       " 6628: 25,\n",
       " 6636: 132,\n",
       " 6654: 21,\n",
       " 6674: 108,\n",
       " 6709: 153,\n",
       " 6727: 71,\n",
       " 6745: 35,\n",
       " 6768: 62,\n",
       " 6770: 154,\n",
       " 6788: 75,\n",
       " 6814: 60,\n",
       " 6825: 141,\n",
       " 6840: 73,\n",
       " 6868: 109,\n",
       " 6877: 86,\n",
       " 6885: 169,\n",
       " 6886: 56,\n",
       " 6959: 120,\n",
       " 6964: 164,\n",
       " 7019: 89,\n",
       " 7061: 105,\n",
       " 7104: 60,\n",
       " 7124: 47,\n",
       " 7128: 76,\n",
       " 7153: 94,\n",
       " 7208: 72,\n",
       " 7210: 215,\n",
       " 7237: 58,\n",
       " 7251: 33,\n",
       " 7261: 81,\n",
       " 7271: 66,\n",
       " 7296: 52,\n",
       " 7303: 27,\n",
       " 7331: 139,\n",
       " 7373: 32,\n",
       " 7399: 424,\n",
       " 7402: 292,\n",
       " 7469: 125,\n",
       " 7496: 391,\n",
       " 7508: 75,\n",
       " 7509: 189,\n",
       " 7532: 84,\n",
       " 7586: 118,\n",
       " 7595: 85,\n",
       " 7608: 72,\n",
       " 7618: 89,\n",
       " 7661: 84,\n",
       " 7688: 210,\n",
       " 7710: 24,\n",
       " 7721: 130,\n",
       " 7782: 110,\n",
       " 7809: 65,\n",
       " 7818: 108,\n",
       " 7878: 247,\n",
       " 7898: 70,\n",
       " 7977: 352,\n",
       " 8019: 331,\n",
       " 8084: 46,\n",
       " 8086: 127,\n",
       " 8088: 33,\n",
       " 8091: 9,\n",
       " 8107: 108,\n",
       " 8188: 99,\n",
       " 8220: 111,\n",
       " 8247: 436,\n",
       " 8265: 127,\n",
       " 8276: 110,\n",
       " 8299: 129,\n",
       " 8304: 227,\n",
       " 8311: 96,\n",
       " 8328: 67,\n",
       " 8355: 24,\n",
       " 8356: 65,\n",
       " 8369: 72,\n",
       " 8388: 112,\n",
       " 8405: 64,\n",
       " 8418: 55,\n",
       " 8431: 54,\n",
       " 8434: 301,\n",
       " 8437: 69,\n",
       " 8461: 103,\n",
       " 8463: 66,\n",
       " 8475: 68,\n",
       " 8605: 96,\n",
       " 8612: 540,\n",
       " 8624: 206,\n",
       " 8656: 164,\n",
       " 8688: 50,\n",
       " 8696: 82,\n",
       " 8702: 177,\n",
       " 8735: 175,\n",
       " 8754: 58,\n",
       " 8821: 56,\n",
       " 8850: 36,\n",
       " 8973: 120,\n",
       " 8982: 180,\n",
       " 9011: 42,\n",
       " 9024: 24,\n",
       " 9025: 84,\n",
       " 9055: 162,\n",
       " 9058: 98,\n",
       " 9094: 68,\n",
       " 9099: 124,\n",
       " 9280: 79,\n",
       " 9287: 99,\n",
       " 9292: 144,\n",
       " 9368: 66,\n",
       " 9369: 86,\n",
       " 9410: 90,\n",
       " 9431: 40,\n",
       " 9436: 122,\n",
       " 9447: 127,\n",
       " 9473: 82,\n",
       " 9476: 124,\n",
       " 9501: 61,\n",
       " 9509: 116,\n",
       " 9526: 72,\n",
       " 9547: 27,\n",
       " 9597: 92,\n",
       " 9653: 39,\n",
       " 9702: 132,\n",
       " 9771: 162,\n",
       " 9789: 115,\n",
       " 9797: 63,\n",
       " 9829: 69,\n",
       " 9843: 43,\n",
       " 9846: 52,\n",
       " 9849: 77,\n",
       " 9864: 43,\n",
       " 9924: 39,\n",
       " 9925: 101,\n",
       " 9945: 15,\n",
       " 9960: 142,\n",
       " 9976: 73,\n",
       " 9977: 102,\n",
       " 9980: 29,\n",
       " 9989: 121,\n",
       " 9998: 34,\n",
       " 127: 19,\n",
       " 226: 32,\n",
       " 235: 118,\n",
       " 249: 22,\n",
       " 322: 58,\n",
       " 328: 53,\n",
       " 335: 53,\n",
       " 409: 19,\n",
       " 482: 8,\n",
       " 551: 20,\n",
       " 604: 85,\n",
       " 752: 12,\n",
       " 801: 89,\n",
       " 803: 23,\n",
       " 817: 104,\n",
       " 842: 43,\n",
       " 1008: 28,\n",
       " 1084: 125,\n",
       " 1158: 30,\n",
       " 1251: 46,\n",
       " 1494: 66,\n",
       " 1501: 38,\n",
       " 1507: 74,\n",
       " 1524: 53,\n",
       " 1670: 21,\n",
       " 1860: 77,\n",
       " 1872: 27,\n",
       " 2073: 51,\n",
       " 2121: 24,\n",
       " 2175: 54,\n",
       " 2198: 37,\n",
       " 2265: 76,\n",
       " 2369: 29,\n",
       " 2517: 28,\n",
       " 2551: 9,\n",
       " 2599: 35,\n",
       " 2874: 14,\n",
       " 2882: 13,\n",
       " 2911: 46,\n",
       " 2944: 33,\n",
       " 2954: 68,\n",
       " 3191: 19,\n",
       " 3224: 33,\n",
       " 3396: 116,\n",
       " 3427: 73,\n",
       " 3457: 57,\n",
       " 3477: 52,\n",
       " 3492: 34,\n",
       " 3503: 79,\n",
       " 3528: 79,\n",
       " 3542: 24,\n",
       " 3600: 70,\n",
       " 3715: 25,\n",
       " 3753: 39,\n",
       " 3863: 54,\n",
       " 4094: 34,\n",
       " 4230: 31,\n",
       " 4525: 21,\n",
       " 4561: 20,\n",
       " 4754: 46,\n",
       " 4765: 81,\n",
       " 4924: 41,\n",
       " 4938: 22,\n",
       " 5347: 38,\n",
       " 5367: 566,\n",
       " 5552: 90,\n",
       " 5618: 100,\n",
       " 5731: 77,\n",
       " 5786: 49,\n",
       " 5905: 38,\n",
       " 5976: 106,\n",
       " 5983: 55,\n",
       " 6632: 109,\n",
       " 6728: 67,\n",
       " 6861: 25,\n",
       " 6897: 45,\n",
       " 7030: 134,\n",
       " 7152: 16,\n",
       " 7537: 15,\n",
       " 7716: 41,\n",
       " 7757: 20,\n",
       " 7780: 456,\n",
       " 7952: 45,\n",
       " 8060: 89,\n",
       " 8070: 44,\n",
       " 8190: 163,\n",
       " 8293: 57,\n",
       " 8389: 55,\n",
       " 8462: 74,\n",
       " 8544: 20,\n",
       " 8625: 29,\n",
       " 8749: 109,\n",
       " 8847: 59,\n",
       " 8909: 48,\n",
       " 9233: 46,\n",
       " 9450: 52,\n",
       " 208: 515,\n",
       " 209: 35,\n",
       " 265: 70,\n",
       " 334: 170,\n",
       " 344: 12,\n",
       " 352: 1002,\n",
       " 411: 62,\n",
       " 605: 575,\n",
       " 674: 139,\n",
       " 744: 53,\n",
       " 952: 529,\n",
       " 1052: 67,\n",
       " 1053: 39,\n",
       " 1217: 273,\n",
       " 1286: 466,\n",
       " 1315: 108,\n",
       " 1348: 514,\n",
       " 1363: 78,\n",
       " 1614: 25,\n",
       " 1767: 120,\n",
       " 1865: 101,\n",
       " 1904: 82,\n",
       " 1913: 63,\n",
       " 1978: 48,\n",
       " 2074: 56,\n",
       " 2116: 64,\n",
       " 2154: 28,\n",
       " 2210: 363,\n",
       " 2220: 928,\n",
       " 2232: 82,\n",
       " 2530: 23,\n",
       " 2672: 472,\n",
       " 2743: 21,\n",
       " 2850: 147,\n",
       " 2859: 337,\n",
       " 3085: 81,\n",
       " 3405: 39,\n",
       " 3541: 118,\n",
       " 3602: 162,\n",
       " 3658: 146,\n",
       " 3690: 186,\n",
       " 3770: 196,\n",
       " 3775: 53,\n",
       " 3870: 385,\n",
       " 3972: 40,\n",
       " 4246: 35,\n",
       " 4273: 263,\n",
       " 4290: 51,\n",
       " 4448: 712,\n",
       " 4534: 40,\n",
       " 4624: 66,\n",
       " 4676: 91,\n",
       " 4967: 59,\n",
       " 5027: 37,\n",
       " 5115: 184,\n",
       " 5130: 18,\n",
       " 5169: 118,\n",
       " 5398: 154,\n",
       " 5570: 122,\n",
       " 5757: 137,\n",
       " 5901: 253,\n",
       " 6189: 659,\n",
       " 6501: 74,\n",
       " 6596: 99,\n",
       " 6726: 224,\n",
       " 6798: 169,\n",
       " 7020: 72,\n",
       " 7039: 28,\n",
       " 7093: 67,\n",
       " 7103: 545,\n",
       " 7110: 20,\n",
       " 7123: 92,\n",
       " 7130: 71,\n",
       " 7416: 754,\n",
       " 7636: 305,\n",
       " 7672: 63,\n",
       " 7751: 46,\n",
       " 7791: 574,\n",
       " 7796: 465,\n",
       " 7836: 16,\n",
       " 7911: 526,\n",
       " 7980: 189,\n",
       " 8034: 378,\n",
       " 8138: 586,\n",
       " 8158: 83,\n",
       " 8163: 101,\n",
       " 8321: 56,\n",
       " 8481: 477,\n",
       " 8490: 23,\n",
       " 8582: 838,\n",
       " 8594: 48,\n",
       " 8599: 129,\n",
       " 8637: 98,\n",
       " 8717: 18,\n",
       " 8762: 390,\n",
       " 8772: 249,\n",
       " 8843: 38,\n",
       " 8853: 40,\n",
       " 9095: 135,\n",
       " 9162: 472,\n",
       " 9186: 483,\n",
       " 9487: 349,\n",
       " 9492: 53,\n",
       " 9584: 48,\n",
       " 9676: 149,\n",
       " 9847: 140,\n",
       " 52: 453,\n",
       " 174: 109,\n",
       " 310: 467,\n",
       " 394: 79,\n",
       " 396: 385,\n",
       " 630: 264,\n",
       " 635: 34,\n",
       " 658: 27,\n",
       " 700: 73,\n",
       " 733: 216,\n",
       " 916: 204,\n",
       " 1161: 160,\n",
       " 1220: 32,\n",
       " 1248: 261,\n",
       " 1281: 417,\n",
       " 1334: 688,\n",
       " 1354: 375,\n",
       " 1407: 233,\n",
       " 1597: 363,\n",
       " 1691: 255,\n",
       " 1739: 260,\n",
       " 1816: 414,\n",
       " 1828: 341,\n",
       " 1948: 287,\n",
       " 2091: 576,\n",
       " 2098: 182,\n",
       " 2103: 16,\n",
       " 2276: 229,\n",
       " 2403: 302,\n",
       " 2610: 468,\n",
       " 2616: 391,\n",
       " 2657: 329,\n",
       " 2686: 363,\n",
       " 2734: 257,\n",
       " 2842: 245,\n",
       " 2926: 380,\n",
       " 3165: 369,\n",
       " 3181: 269,\n",
       " 3207: 365,\n",
       " 3241: 210,\n",
       " 3310: 295,\n",
       " 3346: 310,\n",
       " 3462: 310,\n",
       " 3567: 494,\n",
       " 3689: 76,\n",
       " 3787: 105,\n",
       " 4160: 325,\n",
       " 4192: 310,\n",
       " 4257: 18,\n",
       " 4270: 322,\n",
       " 4284: 518,\n",
       " 4289: 337,\n",
       " 4554: 426,\n",
       " 4636: 458,\n",
       " 4639: 610,\n",
       " 4719: 195,\n",
       " 4727: 414,\n",
       " 4868: 11,\n",
       " 5138: 399,\n",
       " 5221: 217,\n",
       " 5272: 439,\n",
       " 5291: 422,\n",
       " 5375: 477,\n",
       " 5531: 817,\n",
       " 5639: 40,\n",
       " 5697: 414,\n",
       " 5728: 244,\n",
       " 5879: 365,\n",
       " 5943: 479,\n",
       " 5978: 229,\n",
       " 6175: 593,\n",
       " 6201: 242,\n",
       " 6230: 532,\n",
       " 6270: 348,\n",
       " 6451: 367,\n",
       " 6520: 27,\n",
       " 6525: 325,\n",
       " 6682: 301,\n",
       " 6735: 237,\n",
       " 6748: 16,\n",
       " 7028: 337,\n",
       " 7321: 367,\n",
       " 7338: 204,\n",
       " 7343: 329,\n",
       " 7452: 356,\n",
       " 7470: 166,\n",
       " 7522: 361,\n",
       " 7673: 66,\n",
       " 7921: 245,\n",
       " 7969: 386,\n",
       " 7998: 421,\n",
       " 8092: 617,\n",
       " 8099: 285,\n",
       " 8193: 52,\n",
       " 8577: 192,\n",
       " 8654: 351,\n",
       " 8698: 327,\n",
       " 8949: 329,\n",
       " 8997: 73,\n",
       " 9019: 473,\n",
       " 9139: 402,\n",
       " 9185: 37,\n",
       " 9262: 508,\n",
       " 9386: 234,\n",
       " 9387: 268,\n",
       " 9391: 262,\n",
       " 9426: 62,\n",
       " 9724: 210,\n",
       " 9735: 61,\n",
       " 9931: 579,\n",
       " 62: 126,\n",
       " 89: 23,\n",
       " 246: 30,\n",
       " 286: 31,\n",
       " 317: 684,\n",
       " 349: 58,\n",
       " 503: 18,\n",
       " 510: 26,\n",
       " 546: 26,\n",
       " 799: 45,\n",
       " 802: 16,\n",
       " 809: 141,\n",
       " 864: 31,\n",
       " 986: 26,\n",
       " 1015: 16,\n",
       " 1072: 50,\n",
       " 1328: 13,\n",
       " 1352: 13,\n",
       " 1375: 43,\n",
       " 1377: 35,\n",
       " 1658: 35,\n",
       " 2013: 26,\n",
       " 2088: 80,\n",
       " 2115: 564,\n",
       " 2166: 60,\n",
       " 2291: 117,\n",
       " 2537: 28,\n",
       " 2592: 34,\n",
       " 2634: 33,\n",
       " 2671: 17,\n",
       " 2692: 107,\n",
       " 2698: 44,\n",
       " 2953: 44,\n",
       " 3140: 69,\n",
       " 3418: 74,\n",
       " 3589: 20,\n",
       " 3688: 55,\n",
       " 3755: 11,\n",
       " 3947: 60,\n",
       " 4026: 36,\n",
       " 4028: 58,\n",
       " 4327: 174,\n",
       " 4410: 48,\n",
       " 4543: 28,\n",
       " 4548: 36,\n",
       " 4564: 176,\n",
       " 4591: 24,\n",
       " 4602: 12,\n",
       " 4608: 52,\n",
       " 4645: 105,\n",
       " 4708: 89,\n",
       " 4714: 24,\n",
       " 4740: 51,\n",
       " 4744: 32,\n",
       " 4831: 125,\n",
       " 4968: 49,\n",
       " 4977: 61,\n",
       " 5015: 18,\n",
       " 5020: 37,\n",
       " 5035: 95,\n",
       " 5072: 87,\n",
       " 5234: 30,\n",
       " 5564: 77,\n",
       " 5591: 45,\n",
       " 5814: 18,\n",
       " 5867: 16,\n",
       " 5940: 67,\n",
       " 6008: 38,\n",
       " 6042: 128,\n",
       " 6089: 126,\n",
       " 6157: 15,\n",
       " 6207: 62,\n",
       " 6209: 49,\n",
       " 6377: 65,\n",
       " 6415: 46,\n",
       " 6456: 43,\n",
       " 6468: 51,\n",
       " 6650: 52,\n",
       " 6676: 52,\n",
       " 6684: 162,\n",
       " 7029: 42,\n",
       " 7122: 50,\n",
       " 7211: 62,\n",
       " 7295: 152,\n",
       " 7395: 94,\n",
       " 7444: 121,\n",
       " 7455: 35,\n",
       " 7616: 33,\n",
       " 7682: 152,\n",
       " 7713: 26,\n",
       " 7776: 46,\n",
       " 7797: 106,\n",
       " 7811: 35,\n",
       " 7817: 16,\n",
       " 7857: 27,\n",
       " 7909: 28,\n",
       " 7916: 110,\n",
       " 7917: 167,\n",
       " 7923: 43,\n",
       " 7930: 88,\n",
       " 8089: 47,\n",
       " 8119: 88,\n",
       " 8216: 29,\n",
       " 8224: 125,\n",
       " 8252: 366,\n",
       " 8312: 11,\n",
       " 8336: 36,\n",
       " 8395: 80,\n",
       " 8537: 52,\n",
       " 8792: 42,\n",
       " 8805: 56,\n",
       " 8807: 47,\n",
       " 8895: 32,\n",
       " 8979: 43,\n",
       " 9049: 37,\n",
       " 9100: 26,\n",
       " 9108: 35,\n",
       " 9229: 65,\n",
       " 9316: 16,\n",
       " 9334: 63,\n",
       " 9439: 104,\n",
       " 9472: 9,\n",
       " 9491: 21,\n",
       " 9559: 83,\n",
       " 9623: 13,\n",
       " 9657: 23,\n",
       " 9755: 50,\n",
       " 9812: 72,\n",
       " 9878: 57,\n",
       " 50: 116,\n",
       " 58: 82,\n",
       " 71: 65,\n",
       " 180: 23,\n",
       " 350: 39,\n",
       " 591: 130,\n",
       " 595: 37,\n",
       " 641: 8,\n",
       " 644: 61,\n",
       " 731: 141,\n",
       " 764: 24,\n",
       " 1012: 28,\n",
       " 1044: 141,\n",
       " 1313: 45,\n",
       " 1552: 42,\n",
       " 1604: 11,\n",
       " 2012: 65,\n",
       " 2194: 29,\n",
       " 2302: 39,\n",
       " 2384: 47,\n",
       " 2506: 16,\n",
       " 2514: 202,\n",
       " 2751: 64,\n",
       " 2865: 69,\n",
       " 2952: 49,\n",
       " 3077: 88,\n",
       " 3271: 110,\n",
       " 3341: 78,\n",
       " 3365: 19,\n",
       " 3406: 26,\n",
       " 3577: 35,\n",
       " 3732: 22,\n",
       " 3854: 46,\n",
       " 3898: 18,\n",
       " 3942: 19,\n",
       " 4003: 14,\n",
       " 4065: 17,\n",
       " 4382: 34,\n",
       " 4468: 28,\n",
       " 4794: 23,\n",
       " 4874: 75,\n",
       " 5007: 41,\n",
       " 5332: 63,\n",
       " 5424: 9,\n",
       " 5865: 90,\n",
       " 5869: 51,\n",
       " 5916: 187,\n",
       " 5935: 47,\n",
       " 6124: 15,\n",
       " 6491: 82,\n",
       " 6621: 109,\n",
       " 6828: 15,\n",
       " 6878: 136,\n",
       " 7044: 72,\n",
       " 7064: 80,\n",
       " 7138: 101,\n",
       " ...}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listened_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130398, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get only songs that were listened by at least 120 users \n",
    "remove_songs = []\n",
    "for song, num_listened in listened_count.items():\n",
    "    if num_listened < 120:\n",
    "        remove_songs.append(song)\n",
    "\n",
    "# removing songs from dataframe\n",
    "df = df.loc[~df.song_id.isin(remove_songs)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of all the songs available, songs with play_count less than or equal to 5 are in almost 90% abundance. So for building the recommendation system let us consider only those songs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>play_count</th>\n",
       "      <th>title</th>\n",
       "      <th>release</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>6958</td>\n",
       "      <td>447</td>\n",
       "      <td>1</td>\n",
       "      <td>Daisy And Prudence</td>\n",
       "      <td>Distillation</td>\n",
       "      <td>Erin McKeown</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>6958</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>The Ballad of Michael Valentine</td>\n",
       "      <td>Sawdust</td>\n",
       "      <td>The Killers</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>6958</td>\n",
       "      <td>549</td>\n",
       "      <td>1</td>\n",
       "      <td>I Stand Corrected (Album)</td>\n",
       "      <td>Vampire Weekend</td>\n",
       "      <td>Vampire Weekend</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>6958</td>\n",
       "      <td>703</td>\n",
       "      <td>1</td>\n",
       "      <td>They Might Follow You</td>\n",
       "      <td>Tiny Vipers</td>\n",
       "      <td>Tiny Vipers</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>6958</td>\n",
       "      <td>719</td>\n",
       "      <td>1</td>\n",
       "      <td>Monkey Man</td>\n",
       "      <td>You Know I'm No Good</td>\n",
       "      <td>Amy Winehouse</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  song_id  play_count                            title  \\\n",
       "200     6958      447           1               Daisy And Prudence   \n",
       "202     6958      512           1  The Ballad of Michael Valentine   \n",
       "203     6958      549           1        I Stand Corrected (Album)   \n",
       "204     6958      703           1            They Might Follow You   \n",
       "205     6958      719           1                       Monkey Man   \n",
       "\n",
       "                  release      artist_name  year  \n",
       "200          Distillation     Erin McKeown  2000  \n",
       "202               Sawdust      The Killers  2004  \n",
       "203       Vampire Weekend  Vampire Weekend  2007  \n",
       "204           Tiny Vipers      Tiny Vipers  2007  \n",
       "205  You Know I'm No Good    Amy Winehouse  2007  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.play_count<=5]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>play_count</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72473</td>\n",
       "      <td>72473</td>\n",
       "      <td>72473</td>\n",
       "      <td>72473</td>\n",
       "      <td>72473</td>\n",
       "      <td>72473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23890</td>\n",
       "      <td>23890</td>\n",
       "      <td>23890</td>\n",
       "      <td>23890</td>\n",
       "      <td>23890</td>\n",
       "      <td>23890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10774</td>\n",
       "      <td>10774</td>\n",
       "      <td>10774</td>\n",
       "      <td>10774</td>\n",
       "      <td>10774</td>\n",
       "      <td>10774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5874</td>\n",
       "      <td>5874</td>\n",
       "      <td>5874</td>\n",
       "      <td>5874</td>\n",
       "      <td>5874</td>\n",
       "      <td>5874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4865</td>\n",
       "      <td>4865</td>\n",
       "      <td>4865</td>\n",
       "      <td>4865</td>\n",
       "      <td>4865</td>\n",
       "      <td>4865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id  song_id  title  release  artist_name   year\n",
       "play_count                                                      \n",
       "1             72473    72473  72473    72473        72473  72473\n",
       "2             23890    23890  23890    23890        23890  23890\n",
       "3             10774    10774  10774    10774        10774  10774\n",
       "4              5874     5874   5874     5874         5874   5874\n",
       "5              4865     4865   4865     4865         4865   4865"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('play_count').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117876, 7)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exploratory Data Analysis**\n",
    "### **Let's check the total number of unique users, songs, artists in the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3155"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of unique user_id\n",
    "df.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "563"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of unique song_id\n",
    "df.song_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of unique artists\n",
    "df.artist_name.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Let's find out about the most interacted songs and interacted users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Use Somebody                       751\n",
       "Dog Days Are Over (Radio Edit)     748\n",
       "Sehr kosmisch                      713\n",
       "Clocks                             662\n",
       "The Scientist                      652\n",
       "                                  ... \n",
       "Who's Real                         103\n",
       "Brave The Elements                 102\n",
       "Creil City                         101\n",
       "Heaven Must Be Missing An Angel     97\n",
       "The Big Gundown                     96\n",
       "Name: title, Length: 561, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most interacted songs\n",
    "df.title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61472    243\n",
       "15733    227\n",
       "37049    202\n",
       "9570     184\n",
       "23337    177\n",
       "        ... \n",
       "19776      1\n",
       "45476      1\n",
       "17961      1\n",
       "14439      1\n",
       "10412      1\n",
       "Name: user_id, Length: 3155, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most interacted users\n",
    "df.user_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>7592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>13750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>14031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>16351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>4087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      title\n",
       "year       \n",
       "2006   7592\n",
       "2007  13750\n",
       "2008  14031\n",
       "2009  16351\n",
       "2010   4087"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of songs played by year\n",
    "count_songs = df.groupby('year')['title'].count()\n",
    "count = pd.DataFrame(count_songs)\n",
    "count.drop(count.index[0], inplace=True)\n",
    "count.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2160x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "sns.barplot(x=count.index, y='title', data=count)\n",
    "plt.title('Titles played by year', size=30)\n",
    "plt.ylabel('number of titles played')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Proposed Approach:**\n",
    "\n",
    "- **Potential Techniques** - We can explore popularity-based, similarity-based collaborative filtering(user-user and item-item), matrix factorization, clustering-based, and content-based recommendation systems.\n",
    "\n",
    "- **Solution design:** \n",
    "  - Exploring the data and getting key insights\n",
    "  - Applying the above mentioned five techniques and getting recommendations\n",
    "  - Evaluating it on the F_1 score metric\n",
    "  - Getting the best technique\n",
    "  - Summary of potential benefits \n",
    "  - Recommendation for implementation \n",
    "\n",
    "- **The measure of success** - We will use F_1 score to calculate the effectiveness of the recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that we have explored the data, let's apply different algorithms to build recommendation systems**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity Based Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we have now explored the data, let's start building Recommendation systems\n",
    "\n",
    "### Model 1: **Create Rank-Based Recommendation System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank-based recommendation systems provide recommendations based on the most popular songs. This kind of recommendation system is useful when we have **cold start** problems. Cold start refers to the issue when we get a new user into the system and the machine is not able to recommend songs to the new user, as the user did not have any historical interactions in the dataset. In those cases, we can use a rank-based recommendation system to recommend songs to the new user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build the rank-based recommendation system, we take **average** of all the play_counts provided to each song and then rank them based on their average play_counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_count</th>\n",
       "      <th>play_freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.622642</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.492424</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.729216</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1.728070</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1.452174</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_count  play_freq\n",
       "song_id                      \n",
       "21        1.622642        265\n",
       "22        1.492424        132\n",
       "52        1.729216        421\n",
       "62        1.728070        114\n",
       "93        1.452174        115"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the average play_count\n",
    "average_count = df.groupby('song_id')['play_count'].mean()\n",
    "\n",
    "# calculating the frequency a song is played\n",
    "play_freq = df.groupby('song_id')['play_count'].count()\n",
    "\n",
    "# dataframe of average_count and play_freq\n",
    "final_play = pd.DataFrame({'avg_count':average_count, 'play_freq':play_freq})\n",
    "\n",
    "final_play.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a function to find the **top n songs** for a recommendation based on the average play count of song. We can also add a **threshold for a minimum number of playcounts** for a song to be considered for recommendation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_songs(data, n, min_interactions=100):\n",
    "    \"\"\"Recommends songs based on popularity -> average play_count and play_freq\n",
    "\n",
    "    Args:\n",
    "        data (dataframe): dataframe with song is, average play_count and play_freq\n",
    "        n (int): number of songs that will be recommended\n",
    "        min_interactions (int, optional): minimal play_freq to be considered. Defaults to 100.\n",
    "    \"\"\"\n",
    "    \n",
    "    # finding songs with minimum number of play_counts\n",
    "    recommendations = data[data['play_freq'] > min_interactions]\n",
    "\n",
    "    # sorting values w.r.t average count\n",
    "    recommendations = recommendations.sort_values(by='avg_count', ascending=False)\n",
    "\n",
    "    # returns first n songs\n",
    "    return recommendations.index[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can **use this function with different n's and minimum interactions** to get songs to recommend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recommending top 10 Songs with 100 minimum interactions based on popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7224, 6450, 9942, 5531, 5653, 8483, 2220, 657, 614, 352]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(top_n_songs(final_play, 10, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Collaborative Filtering Based Recommendation System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this type of recommendation system, `we do not need any information` about the users or songs. We only need user item interaction data to build a collaborative recommendation system. For example - \n",
    "<ol>\n",
    "    <li><b>Ratings</b> provided by users. For example - ratings of books on goodread, movie ratings on imdb etc</li>\n",
    "    <li><b>Likes</b> of users on different facebook posts, likes on youtube videos</li>\n",
    "    <li><b>Use/buying</b> of a product by users. For example - buying different items on e-commerce sites</li>\n",
    "    <li><b>Reading</b> of articles by readers on various blogs</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types of Collaborative Filtering\n",
    " * Similarity/Neighborhood based\n",
    " * User User Similarity Based  \n",
    " * Item Item similarity based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a baseline user user similarity based recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Below we are building **similarity-based recommendation systems** using `Pearson` similarity and using **KNN to find similar users** which are the nearest neighbor to the given user.  \n",
    "- We will be using a new library - `surprise` to build the remaining models, let's first import the necessary classes and functions from this library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: surprise in /Users/thiagomacedo/opt/anaconda3/lib/python3.9/site-packages (0.1)\n",
      "Requirement already satisfied: scikit-surprise in /Users/thiagomacedo/opt/anaconda3/lib/python3.9/site-packages (from surprise) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.11.2 in /Users/thiagomacedo/opt/anaconda3/lib/python3.9/site-packages (from scikit-surprise->surprise) (1.20.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/thiagomacedo/opt/anaconda3/lib/python3.9/site-packages (from scikit-surprise->surprise) (1.16.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/thiagomacedo/opt/anaconda3/lib/python3.9/site-packages (from scikit-surprise->surprise) (1.7.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/thiagomacedo/opt/anaconda3/lib/python3.9/site-packages (from scikit-surprise->surprise) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compute the accuracy of models\n",
    "from surprise import accuracy\n",
    "\n",
    "# class is used to parse a file containing play_counts, data should be in structure - user; item ; play_count\n",
    "from surprise.reader import Reader\n",
    "\n",
    "# class for loading datasets\n",
    "from surprise.dataset import Dataset\n",
    "\n",
    "# for tuning model hyperparameters\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# for splitting the data in train and test dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# for implementing similarity-based recommendation system\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "\n",
    "# for implementing matrix factorization based recommendation system\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "\n",
    "# for implementing KFold cross-validation\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "#For implementing clustering-based recommendation system\n",
    "from surprise import CoClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before building the recommendation systems, let's  go over some basic terminologies we are going to use:\n",
    "**Relevant songs** - A song that is actually **played higher than the threshold (here 1.5)** is relevant, if the **actual play_count is below the threshold then it is a non-relevant song**.  \n",
    "\n",
    "**Recommended song** - A song that's **predicted play_count is higher than the threshold (here 1.5) is a recommended song**, if the **predicted play_count is below the threshold then that song will not be recommended to the user**.  \n",
    "\n",
    "**False Negative (FN)** - It is the **frequency of relevant songs that are not recommended to the user**. If the relevant songs are not recommended to the user, then the user might not listen to the song. This would result in the **loss of opportunity for the service provider** which they would like to minimize.\n",
    "\n",
    "**False Positive (FP)** - It is the **frequency of recommended songs that are actually not relevant**. In this case, the recommendation system is not doing a good job of finding and recommending the relevant songs to the user. This would result in **loss of resources for the service provider** which they would also like to minimize.\n",
    "\n",
    "**Recall** - It is the **fraction of actually relevant songs that are recommended to the user** i.e. if out of 10 relevant songs, 6 are recommended to the user then recall is 0.60. Higher the value of recall better is the model. It is one of the metrics to do the performance assessment of classification models.\n",
    "\n",
    "**Precision** - It is the **fraction of recommended songs that are relevant actually** i.e. if out of 10 recommended items, 6 are found relevant by the user then precision is 0.60. The higher the value of precision better is the model. It is one of the metrics to do the performance assessment of classification models.\n",
    "\n",
    "**While making a recommendation system it becomes customary to look at the performance of the model. In terms of how many recommendations are relevant and vice-versa, below are the two most used performance metrics used in the assessment of recommendation systems.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision@k and Recall@ k\n",
    "**Precision@k** - It is the **fraction of recommended songs that are relevant in `top k` predictions**. Value of k is the number of recommendations to be provided to the user. One can choose a variable number of recommendations to be given to a unique user.  \n",
    "\n",
    "**Recall@k** - It is the **fraction of relevant songs that are recommended to the user in `top k` predictions**.\n",
    "\n",
    "**F1-Score@k** - It is the **harmonic mean of Precision@k and Recall@k**. When **precision@k and recall@k both seem to be important** then it is useful to use this metric because it is representative of both of them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some useful functions\n",
    "- Below function takes the **recommendation model** as input and gives the **precision@k and recall@k** for that model.  \n",
    "- To compute **precision and recall**, **top k** predictions are taken under consideration for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(model, k=30, threshold=1.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # first map the predictions for each user\n",
    "    user_est_true = defaultdict(list)\n",
    "\n",
    "    # making predictions on the test data\n",
    "    predictions = model.test(testset)\n",
    "\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # number of recommended items in top k\n",
    "        n_rec_k = sum((true_r >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set Precision to 0 when n_rec_k is 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set Recall to 0 when n_rel is 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "    \n",
    "    #Mean of all the predicted precisions are calculated.\n",
    "    precision = round((sum(prec for prec in precisions.values()) / len(precisions)),3)\n",
    "    #Mean of all the predicted recalls are calculated.\n",
    "    recall = round((sum(rec for rec in recalls.values()) / len(recalls)),3)\n",
    "    \n",
    "    accuracy.rmse(predictions)\n",
    "    print('Precision: ', precision) #Command to print the overall precision\n",
    "    print('Recall: ', recall) #Command to print the overall recall\n",
    "    print('F_1 score: ', round((2*precision*recall)/(precision+recall),3)) # Formula to compute the F-1 score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are loading the **dataset**, which is a **pandas dataframe**, into a **different format called `surprise.dataset.DatasetAutoFolds`** which is required by this library. To do this we will be **using the classes `Reader` and `Dataset`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing reader scale with expected rating scale\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "\n",
    "# loading the dataset\n",
    "data = Dataset.load_from_df(df[['user_id', 'song_id', 'play_count']], reader)\n",
    "\n",
    "# splitting the data into train and test dataset\n",
    "trainset, testset = train_test_split(data, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we are **ready to build the first baseline similarity-based recommendation system** using the cosine similarity.\n",
    "- **KNNBasic** is an algorithm that is also **associated with the surprise package**, it is used to find the **desired similar songs among a given set of songs**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To compute **precision and recall**, a **threshold of 1.5 and k value of 30 is taken for the recommended and relevant play counts**.  \n",
    "- The intuition of threshold 1.5 is that if the predicts that a user will listen to the song more than 1.5 times(can be understood 2 out of 3 if a non-integer value is getting hard to interpret) then that song should be recommended to that user. \n",
    "- In the **present case precision and recall both need to be optimized as the service provider would like to minimize both the losses discussed** above. Hence, the correct performance measure is the **F_1 score**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0878\n",
      "Precision:  0.305\n",
      "Recall:  0.692\n",
      "F_1 score:  0.423\n"
     ]
    }
   ],
   "source": [
    "# declaring similarity options\n",
    "sim_options = {'name': 'cosine', 'user_based':True}\n",
    "\n",
    "# KNN algorithm is used to find desired similar items\n",
    "sim_user_user = KNNBasic(sim_options=sim_options, verbose=False, random_state=1)\n",
    "\n",
    "# train the algorithm on the trainset, and predict play_count for the testset\n",
    "sim_user_user.fit(trainset)\n",
    "\n",
    "# let's compute precison@k, recall@k, and f_1 score with k=30\n",
    "precision_recall_at_k(sim_user_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have calculated **RMSE** to check **how far the overall predicted play counts** are from the **actual play counts**.\n",
    "- Intuition of Recall - We are getting a **recall of almost 0.70**, which means out of **all the relevant songs, 70% are recommended**. \n",
    "- Intuition of Precision - We are getting a **precision of almost 0.305**, which means **out of all the recommended songs, 30.5% are relevant**.\n",
    "- Here **F_1 score** of the **baseline model is almost 0.423**. It indicates that **mostly recommended songs were relevant and relevant songs were recommended**. We will try to improve this later by using **GridSearchCV by tuning different hyperparameters** of this algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now **predict play_counts for a user with `user_id=6958` and `song_id=1671`** as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 1671       r_ui = 2.00   est = 1.80   {'actual_k': 40, 'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=1671, r_ui=2, est=1.8009387435128914, details={'actual_k': 40, 'was_impossible': False})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_user_user.predict(6958, 1671, r_ui=2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above output shows that **the actual play count for this user-item pair is 2 and the predicted is 1.80** by this **user-user-similarity-based baseline model**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are **predicting play_count for the same `userId=6958` but for a song which this user has not heard yet i.e. `song_id=3232`** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 3232       r_ui = None   est = 1.64   {'actual_k': 40, 'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=3232, r_ui=None, est=1.6386860897998294, details={'actual_k': 40, 'was_impossible': False})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_user_user.predict(6958, 3232, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the **predicted play count for this user-item pair is 1.64** based on this user-user-similarity-based baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving similarity-based recommendation system by tuning its hyper-parameters\n",
    "\n",
    "Below we will be tuning hyperparameters for the `KNNBasic` algorithms. Let's try to understand some of the hyperparameters of the KNNBasic algorithm:\n",
    "\n",
    "- **k** (int) – The (max) number of neighbors to take into account for aggregation. Default is 40.\n",
    "- **min_k** (int) – The minimum number of neighbors to take into account for aggregation. If there are not enough neighbors, the prediction is set to the global mean of all play_counts. Default is 1.\n",
    "- **sim_options** (dict) – A dictionary of options for the similarity measure. And there are four similarity measures available in surprise - \n",
    "    - cosine\n",
    "    - msd (default)\n",
    "    - Pearson\n",
    "    - Pearson baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "1.0473606510139541\n",
      "{'k': 30, 'min_k': 9, 'sim_options': {'name': 'pearson_baseline', 'user_based': True, 'min_support': 2}}\n"
     ]
    }
   ],
   "source": [
    "# setting up parameter grid to tune the hyperparameters\n",
    "param_grid = {'k':[10,20,30], 'min_k':[3,6,9],\n",
    "              'sim_options': {'name':['cosine','pearson','pearson_baseline'],\n",
    "                              'user_based': [True], 'min_support':[2,4]}}\n",
    "\n",
    "# performing 3-fold cross validation to tune the hyperparameters\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "# fitting the data\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the grid search is **complete**, we can get the **optimal values for each of those hyperparameters** as shown above\n",
    "\n",
    "Now let's build the **final model by using tuned values of the hyperparameters** which we received by using **grid search cross-validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0521\n",
      "Precision:  0.32\n",
      "Recall:  0.721\n",
      "F_1 score:  0.443\n"
     ]
    }
   ],
   "source": [
    "# using the optimal similarity measure for user-user based collaborative filtering\n",
    "sim_options = {'name': 'pearson_baseline',\n",
    "               'user_based': True, 'min_support':2}\n",
    "\n",
    "# creating an instance of KNNBasic with optimal hyperparameter values\n",
    "sim_user_user_optimized = KNNBasic(sim_options=sim_options, k=30, min_k=9, random_state=1, verbose=False)\n",
    "\n",
    "# training the algorithm on the trainset\n",
    "sim_user_user_optimized.fit(trainset)\n",
    "\n",
    "# let's compute precision@k and recall@k also with k=30\n",
    "precision_recall_at_k(sim_user_user_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see from above that after tuning hyperparameters, **F_1 score of the tuned model is better than the baseline model.** Along with this **the RMSE of the model has gone down as compared to the model before hyperparameter tuning**. Hence, we can say that the model performance has improved after hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's us now **predict play_count for a user with `userId`=\"6958\", and song_id=1671 with the optimized model as shown below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 1671       r_ui = 2.00   est = 1.96   {'actual_k': 24, 'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=1671, r_ui=2, est=1.962926073914969, details={'actual_k': 24, 'was_impossible': False})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_user_user_optimized.predict(6958, 1671, r_ui=2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here the model gives a **good prediction** in comparison to the actual play_count(2). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are predicting play_count for the same **`userId=\"6958\"`** but for a song which this user has **not listened before** i.e. `song_id=3232`, by using the **optimized model** as shown below - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 3232       r_ui = None   est = 1.45   {'actual_k': 10, 'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=3232, r_ui=None, est=1.4516261428486725, details={'actual_k': 10, 'was_impossible': False})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_user_user_optimized.predict(6958,3232, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying similar users to a given user (nearest neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find out **similar users to a given user** or its **nearest neighbors** based on this KNNBasic algorithm. Below we are finding the 5 most similar users to the first user in the list with internal id 0, based on the `msd` distance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42, 1131, 17, 186, 249]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_user_user_optimized.get_neighbors(0,5) \n",
    "# 0 is the inner id of the above user "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing the recommendation algorithm based on optimized KNNBasic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will be implementing a function where the input parameters are - \n",
    "\n",
    "- data: a **song** dataset\n",
    "- user_id: a user id **against which we want the recommendations**\n",
    "- top_n: the **number of songs we want to recommend**\n",
    "- algo: the algorithm we want to use **for predicting the play_count**\n",
    "- The output of the function is a **set of top_n items** recommended for the given user_id based on the given algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(data, user_id, top_n, algo):\n",
    "\n",
    "    # creating an empty list to store the recomended produt ids\n",
    "    recommendations = []\n",
    "\n",
    "    # creating an user item interactions matrix\n",
    "    user_item_interactions_matrix = data.pivot(index='user_id', columns='song_id', values='play_count')\n",
    "\n",
    "    # extracting those business ids which the user_id has not visited yet\n",
    "    non_interacted_products = user_item_interactions_matrix.loc[user_id][user_item_interactions_matrix.loc[user_id].isnull()].index.tolist()\n",
    "\n",
    "    # looping through each of the business ids which user_id has not interacted yer\n",
    "    for item_id in non_interacted_products:\n",
    "        # predicting the ratings for those non visited restaurant ids by this user\n",
    "        est = algo.predict(user_id, item_id).est\n",
    "\n",
    "        # appending the predicted ratings\n",
    "        recommendations.append((item_id, est))\n",
    "\n",
    "    # sorting the predicted ratings in descending order\n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # return top n highest predited rating products for this user\n",
    "    return recommendations[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted top 5 songs for userId=6958 with user_user_similarity based recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = get_recommendations(df, 6958, 5, sim_user_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>predicted_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7224</td>\n",
       "      <td>3.141147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>614</td>\n",
       "      <td>2.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5653</td>\n",
       "      <td>2.514023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>352</td>\n",
       "      <td>2.425000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6450</td>\n",
       "      <td>2.394927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_id  predicted_ratings\n",
       "0     7224           3.141147\n",
       "1      614           2.525000\n",
       "2     5653           2.514023\n",
       "3      352           2.425000\n",
       "4     6450           2.394927"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(recommendations, columns=['song_id', 'predicted_ratings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting the play_counts and Ranking the above songs\n",
    "While comparing the play counts of two songs, it is not only the **play_counts** that describe the **likelihood of the user to that product**. Along with the play_count the **number of users who have heard that song** also becomes important to consider. Due to this, we have calculated the **\"corrected_ratings\"** for each song. Commonly higher the **\"play_count\" of a product more it is liked by users**. To interpret the above concept, a **song with play count 4 with rating_count 3 is less liked in comparison to a song with play count 3 with a rating count of 50**. It has been **empirically found that the likelihood of the product is directly proportional to the inverse of the square root of the rating_count of the product**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_songs(recommendations, final_rating):\n",
    "    # sort the songs based on play counts\n",
    "    ranked_songs = final_rating.loc[[items[0] for items in recommendations]].sort_values('play_freq', ascending=False)[['play_freq']].reset_index()\n",
    "\n",
    "    # merge with the recommended songs to get predicted play_count\n",
    "    ranked_songs = ranked_songs.merge(pd.DataFrame(recommendations, columns=['song_id', 'predicted_ratings']), on='song_id', how='inner')\n",
    "\n",
    "    # rank the songs based on corrected play_counts\n",
    "    ranked_songs['corrected_ratings'] = ranked_songs['predicted_ratings'] - 1 / np.sqrt(ranked_songs['play_freq'])\n",
    "\n",
    "    # sort the songs based on corrected play_counts\n",
    "    ranked_songs = ranked_songs.sort_values('corrected_ratings', ascending=False)\n",
    "\n",
    "    return ranked_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>play_freq</th>\n",
       "      <th>predicted_ratings</th>\n",
       "      <th>corrected_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7224</td>\n",
       "      <td>107</td>\n",
       "      <td>3.141147</td>\n",
       "      <td>3.044473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>614</td>\n",
       "      <td>373</td>\n",
       "      <td>2.525000</td>\n",
       "      <td>2.473222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5653</td>\n",
       "      <td>108</td>\n",
       "      <td>2.514023</td>\n",
       "      <td>2.417798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>352</td>\n",
       "      <td>748</td>\n",
       "      <td>2.425000</td>\n",
       "      <td>2.388436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6450</td>\n",
       "      <td>102</td>\n",
       "      <td>2.394927</td>\n",
       "      <td>2.295913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_id  play_freq  predicted_ratings  corrected_ratings\n",
       "3     7224        107           3.141147           3.044473\n",
       "1      614        373           2.525000           2.473222\n",
       "2     5653        108           2.514023           2.417798\n",
       "0      352        748           2.425000           2.388436\n",
       "4     6450        102           2.394927           2.295913"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_songs(recommendations, final_play)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item Item Similarity-based collaborative filtering recommendation systems \n",
    "* Above we have seen **similarity-based collaborative filtering** where similarity has seen **between users**. Now let us look into similarity-based collaborative filtering where similarity is seen **between songs**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0588\n",
      "Precision:  0.27\n",
      "Recall:  0.538\n",
      "F_1 score:  0.36\n"
     ]
    }
   ],
   "source": [
    "# declaring the similarity options\n",
    "sim_options = {'name': 'pearson',\n",
    "               'user_based': False}\n",
    "\n",
    "# KNN algorithm is used to find desired similar items\n",
    "sim_item_item = KNNBasic(sim_options=sim_options, random_state=1, verbose=False)\n",
    "\n",
    "# train the algorithm on the trainset, and predict play_count for the testset\n",
    "sim_item_item.fit(trainset)\n",
    "\n",
    "# let us compute precions@k, recall@k, and f_1 score with k=30\n",
    "precision_recall_at_k(sim_item_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The baseline model is giving a good F_1 score. We will try to **improve this later by using GridSearchCV** by tuning different hyperparameters of this algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now **predict the play_count for a user with `userId=6958` and `song_id=1671`** as shown below. Here the user has already heard the song with song_id 1671."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 1671       r_ui = 2.00   est = 1.92   {'actual_k': 10, 'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=1671, r_ui=2, est=1.91669781984001, details={'actual_k': 10, 'was_impossible': False})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_item_item.predict(6958, 1671, r_ui=2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above output shows that **item-item similarity** based model is making a **good prediction** where the actual play_count is 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are **predicting play count for the same userId=6958 but for a song which this user has not heard yet i.e. `song_id=3232`** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 3232       r_ui = None   est = 1.00   {'actual_k': 5, 'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=3232, r_ui=None, est=1.0, details={'actual_k': 5, 'was_impossible': False})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting play count for a sample user with song not heard by the user.\n",
    "sim_item_item.predict(6958,3232, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the **predicted play_count for this user-song pair is low** based on this **item-item similarity-based baseline model**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving similarity-based recommendation system by tuning its hyper-parameters\n",
    "Below we will be **tuning hyperparameters for the `KNNBasic` algorithms**. Let's try to understand **some of the hyperparameters** of the KNNBasic algorithm:\n",
    "- **k** (int) – The (max) number of neighbors to take into account for aggregation. Default is 40.\n",
    "- **min_k** (int) – The minimum number of neighbors to take into account for aggregation. If there are not enough neighbors, the prediction is set to the global mean of all play_counts. Default is 1.\n",
    "- **sim_options** (dict) – A dictionary of options for the similarity measure. And there are four similarity measures available in surprise - \n",
    "    - cosine\n",
    "    - msd (default)\n",
    "    - Pearson\n",
    "    - Pearson baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "1.0253076284754619\n",
      "{'k': 30, 'min_k': 6, 'sim_options': {'name': 'pearson_baseline', 'user_based': False, 'min_support': 2}}\n"
     ]
    }
   ],
   "source": [
    "# setting up parameter grid to tune the hyperparameters\n",
    "param_grid = {'k': [10, 20, 30], 'min_k': [3, 6, 9],\n",
    "              'sim_options': {'name': [\"cosine\",'pearson',\"pearson_baseline\"],\n",
    "                              'user_based': [False], \"min_support\":[2,4]}\n",
    "              }\n",
    "\n",
    "# performing 3-fold cross validation to tune the hyperparameters\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "# fitting the data\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the **grid search** is complete, we can get the **optimal values for each of those hyperparameters as shown above**\n",
    "\n",
    "Now let's build the **final model** by using **tuned values of the hyperparameters** which we received by using grid search cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0328\n",
      "Precision:  0.327\n",
      "Recall:  0.696\n",
      "F_1 score:  0.445\n"
     ]
    }
   ],
   "source": [
    "# using the optimal similarity measure for item-item based collaborative filtering\n",
    "sim_options = {'name': 'pearson_baseline',\n",
    "               'user_based': False, \"min_support\":4}\n",
    "\n",
    "# creating an instance of KNNBasic with optimal hyperparameter values\n",
    "sim_item_item_optimized = KNNBasic(sim_options=sim_options, k=30, min_k=6, random_state=1, verbose=False)\n",
    "\n",
    "# training the algorithm on the trainset\n",
    "sim_item_item_optimized.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k and recall@k also with k =10.\n",
    "precision_recall_at_k(sim_item_item_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see from above that after tuning hyperparameters, **F_1 score of the tuned model is much better than the baseline model**. Also, there is a considerable fall in the RMSE value with tuning. Hence the tuned model is doing better than the earlier one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's us now predict **play_count for an user with `userId=6958` and for `songs_id=1671`** with the **optimized model** as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 1671       r_ui = 2.00   est = 1.96   {'actual_k': 10, 'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=1671, r_ui=2, est=1.9634957386781853, details={'actual_k': 10, 'was_impossible': False})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_item_item_optimized.predict(6958, 1671, r_ui=2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here the optimized model is predicting a very good play_count (almost **1.96**) for the product whose actual play_count is 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are **predicting play_count** for the same **`userId=6958`** but for a song which this user **has not listened before** i.e. `songs_id==3232`, by using the optimized model as shown below - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 3232       r_ui = None   est = 1.70   {'was_impossible': True, 'reason': 'Not enough neighbors.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=3232, r_ui=None, est=1.6989607635206787, details={'was_impossible': True, 'reason': 'Not enough neighbors.'})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_item_item_optimized.predict(6958, 3232, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For an unknown product the model is predicting a play_count of **1.70**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find out **similar users** to a given user or its nearest neighbors based on this **KNNBasic algorithm**. Below we are finding 5 most similar users to the user with internal id 0 based on the `msd` distance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[124, 523, 173, 205, 65]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_item_item_optimized.get_neighbors(0, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted top 5 products for userId=6958 with similarity based recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making top 5 recommendations for user_id 6958 with similarity-based recommendation engine.\n",
    "recommendations = get_recommendations(df, 6958, 5, sim_item_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>songs_id</th>\n",
       "      <th>predicted_play_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>750</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4377</td>\n",
       "      <td>4.206578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139</td>\n",
       "      <td>3.875420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5616</td>\n",
       "      <td>3.868549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>861</td>\n",
       "      <td>3.840408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   songs_id  predicted_play_count\n",
       "0       750              5.000000\n",
       "1      4377              4.206578\n",
       "2       139              3.875420\n",
       "3      5616              3.868549\n",
       "4       861              3.840408"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Building the dataframe for above recommendations with columns \"song_id\" and \"predicted_play_count\"\n",
    "pd.DataFrame(recommendations, columns=['songs_id', 'predicted_play_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>play_freq</th>\n",
       "      <th>predicted_ratings</th>\n",
       "      <th>corrected_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>750</td>\n",
       "      <td>123</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.909833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4377</td>\n",
       "      <td>159</td>\n",
       "      <td>4.206578</td>\n",
       "      <td>4.127273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>139</td>\n",
       "      <td>119</td>\n",
       "      <td>3.875420</td>\n",
       "      <td>3.783750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5616</td>\n",
       "      <td>113</td>\n",
       "      <td>3.868549</td>\n",
       "      <td>3.774477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>861</td>\n",
       "      <td>126</td>\n",
       "      <td>3.840408</td>\n",
       "      <td>3.751321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_id  play_freq  predicted_ratings  corrected_ratings\n",
       "2      750        123           5.000000           4.909833\n",
       "0     4377        159           4.206578           4.127273\n",
       "3      139        119           3.875420           3.783750\n",
       "4     5616        113           3.868549           3.774477\n",
       "1      861        126           3.840408           3.751321"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying the ranking_songs function and sorting it based on corrected play_counts. \n",
    "ranking_songs(recommendations, final_play)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now as we have seen **similarity-based collaborative filtering algorithms**, let us now get into **model-based collaborative filtering algorithms**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Based Collaborative Filtering - Matrix Factorization\n",
    "Model-based Collaborative Filtering is a **personalized recommendation system**, the recommendations are based on the past behavior of the user and it is not dependent on any additional information. We use **latent features** to find recommendations for each user.\n",
    "#### Singular Value Decomposition (SVD)\n",
    "SVD is used to **compute the latent features** from the **user-song matrix**. But SVD does not work when we **miss values** in the **user-item matrix**.\n",
    "#### Building a baseline matrix factorization recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0252\n",
      "Precision:  0.303\n",
      "Recall:  0.633\n",
      "F_1 score:  0.41\n"
     ]
    }
   ],
   "source": [
    "# using SVD matrix factorization\n",
    "svd = SVD(random_state=1)\n",
    "\n",
    "# training the algorithm on the trainset\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k and recall@k with k =30.\n",
    "precision_recall_at_k(svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The baseline model with the algorithm is giving a nice F-1 score (almost **41%**). It indicates a good performance by the model. The RMSE of the model is 1.0252."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's now predict the play_count for a user with `userId=\"6958\"` and `song_id=1671 as shown below\n",
    "- Here the user has already heard the song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 1671       r_ui = 2.00   est = 1.27   {'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=1671, r_ui=2, est=1.267473397214638, details={'was_impossible': False})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making prediction.\n",
    "svd.predict(6958, 1671, r_ui=2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see - **the actual play_counts** for this user-song pair is 2 and the predicted play_count is **1.27** by this matrix **factorization-based baseline model**. It seems like we have under-estimated the play_count. We will try to fix this later by **tuning the hyperparameters** of the model using GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are predicting play_count for the same `userId=6958` but for a song which this user has not listened before i.e. `song_id=3232`, as shown below - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 3232       r_ui = None   est = 1.56   {'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=3232, r_ui=None, est=1.5561675084403663, details={'was_impossible': False})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making prediction. \n",
    "svd.predict(6958, 3232, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the **estimated play_count** for this **user-song pair** is 1.98 based on this **matrix factorization based baseline model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving matrix factorization based recommendation system by tuning its hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In SVD, play_count is predicted as - \n",
    "$$\\hat{r}_{u i}=\\mu+b_{u}+b_{i}+q_{i}^{T} p_{u}$$\n",
    "If user $u$ is unknown, then the bias $b_{u}$ and the factors $p_{u}$ are assumed to be zero. The same applies for item $i$ with $b_{i}$ and $q_{i}$.\n",
    "To estimate all the unknown, we minimize the following regularized squared error:\n",
    "$$\\sum_{r_{u i} \\in R_{\\text {train }}}\\left(r_{u i}-\\hat{r}_{u i}\\right)^{2}+\\lambda\\left(b_{i}^{2}+b_{u}^{2}+\\left\\|q_{i}\\right\\|^{2}+\\left\\|p_{u}\\right\\|^{2}\\right)$$\n",
    "The minimization is performed by a very straightforward **stochastic gradient descent**:\n",
    "$$\\begin{aligned} b_{u} & \\leftarrow b_{u}+\\gamma\\left(e_{u i}-\\lambda b_{u}\\right) \\\\ b_{i} & \\leftarrow b_{i}+\\gamma\\left(e_{u i}-\\lambda b_{i}\\right) \\\\ p_{u} & \\leftarrow p_{u}+\\gamma\\left(e_{u i} \\cdot q_{i}-\\lambda p_{u}\\right) \\\\ q_{i} & \\leftarrow q_{i}+\\gamma\\left(e_{u i} \\cdot p_{u}-\\lambda q_{i}\\right) \\end{aligned}$$\n",
    "There are many hyperparameters to tune in this algorithm, you can find a full list of hyperparameters [here](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD)\n",
    "Below we will be tuning only three hyperparameters -\n",
    "- **n_epochs**: The number of iteration of the SGD algorithm\n",
    "- **lr_all**: The learning rate for all parameters\n",
    "- **reg_all**: The regularization term for all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.012738973514167\n",
      "{'n_epochs': 30, 'lr_all': 0.01, 'reg_all': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# set the parameter space to tune\n",
    "param_grid = {'n_epochs': [10, 20, 30], 'lr_all': [0.001, 0.005, 0.01],\n",
    "              'reg_all': [0.2, 0.4, 0.6]}\n",
    "\n",
    "# performing 3-fold gridsearch cross validation\n",
    "gs_ = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "# fitting data\n",
    "gs_.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs_.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs_.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the **grid search** is complete, we can get the **optimal values** for each of those hyperparameters as shown above\n",
    "\n",
    "Now we will **build the final model** by using **tuned values** of the hyperparameters which we received by using grid search cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0141\n",
      "Precision:  0.307\n",
      "Recall:  0.635\n",
      "F_1 score:  0.414\n"
     ]
    }
   ],
   "source": [
    "svd_optimized = SVD(n_epochs=30, lr_all=0.01, reg_all=0.2, random_state=1)\n",
    "\n",
    "svd_optimized = svd_optimized.fit(trainset)\n",
    "\n",
    "precision_recall_at_k(svd_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see from above that the **tuned model** is showing a slightly better F_1 score and also a very slight growth is there in the model. Hence the tuned model is doing better than the earlier model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now predict the play_count for a user with `userId=6958` and `song_id=1671` with the optimized model as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 1671       r_ui = 2.00   est = 1.34   {'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=1671, r_ui=2, est=1.3432395286125096, details={'was_impossible': False})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using svd_algo_optimized model to recommend for userId 6958 and song_id 1671.\n",
    "svd_optimized.predict(6958, 1671, r_ui=2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the predicted play_count is **1.34** for a song whose actual play_count is **2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 3232       r_ui = None   est = 1.44   {'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=3232, r_ui=None, est=1.442548446117648, details={'was_impossible': False})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using svd_algo_optimized model to recommend for userId 6958 and song_id 3232 with unknown baseline rating.\n",
    "svd_optimized.predict(6958, 3232, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an unseen song the play_count given by the optimized model is **1.44**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting top 5 recommendations for user_id 6958 using \"svd_optimized\" algorithm.\n",
    "svd_recommendations = get_recommendations(df, 6958, 5, svd_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>play_freq</th>\n",
       "      <th>predicted_ratings</th>\n",
       "      <th>corrected_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7224</td>\n",
       "      <td>107</td>\n",
       "      <td>2.601899</td>\n",
       "      <td>2.505225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5653</td>\n",
       "      <td>108</td>\n",
       "      <td>2.108728</td>\n",
       "      <td>2.012502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8324</td>\n",
       "      <td>96</td>\n",
       "      <td>2.014091</td>\n",
       "      <td>1.912029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9942</td>\n",
       "      <td>150</td>\n",
       "      <td>1.940115</td>\n",
       "      <td>1.858465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6450</td>\n",
       "      <td>102</td>\n",
       "      <td>1.952493</td>\n",
       "      <td>1.853478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_id  play_freq  predicted_ratings  corrected_ratings\n",
       "2     7224        107           2.601899           2.505225\n",
       "1     5653        108           2.108728           2.012502\n",
       "4     8324         96           2.014091           1.912029\n",
       "0     9942        150           1.940115           1.858465\n",
       "3     6450        102           1.952493           1.853478"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ranking songs based on above recommendations\n",
    "ranking_songs(svd_recommendations, final_play)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "In this case study, we built recommendation systems using five different algorithms. They are as follows:\n",
    "- rank-based using averages\n",
    "- User-user-similarity-based collaborative filtering\n",
    "- Item-item-similarity-based collaborative filtering\n",
    "- model-based (matrix factorization) collaborative filtering  \n",
    "\n",
    "We have seen how they are different from each other and what kind of data is needed to build each of these recommendation systems. We can further combine all the recommendation techniques we have seen.  \n",
    "To demonstrate **\"user-user-similarity-based collaborative filtering\",\"item-item-similarity-based collaborative filtering\", and \"model-based (matrix factorization) collaborative filtering\"**, **surprise** library has been demonstrated. For these algorithms **grid search cross-validation is used to find the best working model**, and using that the **corresponding predictions are made**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Proposal for the final solution design:**\n",
    "\n",
    "We will use the user-user similarity-based collaborative filtering recommendation system final solution since it is more robust and gives a high F_1 score. We have predicted the play counts for all the users that have not listened to a particular song."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a9f8fe2dbe13acf2a3933ecae393e09c8689df079fdc02936947523c3be48f8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
